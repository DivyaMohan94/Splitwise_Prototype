[2021-04-17 04:11:51,531] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:11:51,536] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-17 04:11:51,539] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-17 04:11:51,571] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2021-04-17 04:11:51,579] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:11:51,580] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:11:51,580] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:11:51,581] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:11:51,588] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:11:51,589] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:11:51,591] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:11:51,594] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:51,704] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:51,704] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:51,705] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2021-04-17 04:11:51,707] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:51,813] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:51,813] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:51,816] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:11:51,818] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:11:51,819] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2021-04-17 04:11:51,819] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:11:51,819] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:11:51,819] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:11:51,820] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:11:51,822] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:11:51,823] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:51,880] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:51,880] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:51,881] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,013] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,013] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,015] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:11:52,016] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-17 04:11:52,017] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:11:52,017] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:11:52,017] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:11:52,018] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:11:52,022] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:11:52,023] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:11:52,023] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:11:52,023] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,152] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,153] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,153] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,223] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,223] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,223] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,266] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,267] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,267] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,301] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,301] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:11:52,338] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-17 04:11:52,339] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:11:52,340] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:11:52,340] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:11:52,341] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:11:52,342] INFO Shutting down. (kafka.log.LogManager)
[2021-04-17 04:11:52,363] INFO [ProducerStateManager partition=getInvites-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,373] INFO [ProducerStateManager partition=settleUp-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,375] INFO [ProducerStateManager partition=login-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,378] INFO [ProducerStateManager partition=getFilteredGroup-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,380] INFO [ProducerStateManager partition=getTransaction-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,382] INFO [ProducerStateManager partition=response_topic-0] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,384] INFO [ProducerStateManager partition=getAllYouOwe-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,385] INFO [ProducerStateManager partition=getAllYouAreOwed-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,387] INFO [ProducerStateManager partition=getFriends-0] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,390] INFO [ProducerStateManager partition=getActiveGroups-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,392] INFO [ProducerStateManager partition=getAllTransactions-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,393] INFO [ProducerStateManager partition=getRecentActivities-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,394] INFO [ProducerStateManager partition=getDashboardDetails-0] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,395] INFO [ProducerStateManager partition=signUp-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,397] INFO [ProducerStateManager partition=getGroupsDropdown-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,399] INFO [ProducerStateManager partition=addExpense-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:11:52,621] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-17 04:11:52,635] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:11:52,635] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:11:52,635] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:11:52,637] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:11:52,749] INFO Session: 0x100251acc630000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:11:52,749] INFO EventThread shut down for session: 0x100251acc630000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:11:52,750] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:11:52,751] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:53,743] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:53,743] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:53,743] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:53,766] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:53,766] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:53,766] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:53,862] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:53,862] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:53,862] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:54,743] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:54,743] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:11:54,745] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-17 04:11:54,780] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-17 04:11:54,781] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:11:54,781] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:11:54,781] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:11:54,787] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2021-04-17 04:11:54,788] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:11:54,789] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-17 04:12:30,603] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:12:30,604] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:12:30,609] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:12:30,609] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:12:30,611] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:12:30,611] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:12:30,611] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:12:30,611] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-17 04:12:30,615] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-17 04:12:30,629] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:12:30,629] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:12:30,630] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:12:30,630] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:12:30,630] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-17 04:12:30,633] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:12:30,643] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,643] INFO Server environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,643] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,643] INFO Server environment:java.vendor=Ubuntu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,643] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,643] INFO Server environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,643] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,643] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,643] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,644] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,644] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,644] INFO Server environment:os.version=5.8.0-48-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,644] INFO Server environment:user.name=divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,644] INFO Server environment:user.home=/home/divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,644] INFO Server environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,644] INFO Server environment:os.memory.free=494MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,644] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,644] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,645] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,645] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,646] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:12:30,653] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-17 04:12:30,656] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:12:30,660] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:12:30,676] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-17 04:12:30,680] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:12:30,683] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:12:30,698] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-17 04:12:40,335] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-17 04:12:40,605] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-17 04:12:40,652] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:12:40,656] INFO starting (kafka.server.KafkaServer)
[2021-04-17 04:12:40,657] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-17 04:12:40,674] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:12:40,678] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,678] INFO Client environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,678] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:os.version=5.8.0-48-generic (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:user.name=divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:user.home=/home/divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,679] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,680] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,680] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,681] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@18ece7f4 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:12:40,686] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-17 04:12:40,690] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:12:40,694] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:12:40,700] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:12:40,704] INFO Socket connection established, initiating session, client: /127.0.0.1:44304, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:12:40,716] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-17 04:12:40,757] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002b0a59360000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:12:40,760] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:12:41,016] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:12:41,045] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:12:41,046] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:12:41,205] INFO Cluster ID = K5p8-7VXQZOpVzm0AQt5PQ (kafka.server.KafkaServer)
[2021-04-17 04:12:41,208] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-04-17 04:12:41,260] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:12:41,270] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:12:41,307] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:12:41,308] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:12:41,310] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:12:41,311] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:12:41,332] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2021-04-17 04:12:41,338] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2021-04-17 04:12:41,340] INFO Attempting recovery for all logs in /tmp/kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2021-04-17 04:12:41,354] INFO Loaded 0 logs in 16ms. (kafka.log.LogManager)
[2021-04-17 04:12:41,375] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-17 04:12:41,377] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-17 04:12:41,736] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:12:41,739] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:12:41,742] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:12:41,745] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-17 04:12:41,783] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:12:41,812] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:12:41,813] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:12:41,814] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:12:41,814] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:12:41,826] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:12:41,826] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:12:41,855] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-17 04:12:41,883] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1618657961870,1618657961870,1,0,0,72104917484306432,220,0,24
 (kafka.zk.KafkaZkClient)
[2021-04-17 04:12:41,884] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://divyamohan-GL552VW:9092, czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2021-04-17 04:12:41,970] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:12:41,974] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:12:41,974] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:12:41,988] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2021-04-17 04:12:42,000] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:12:42,001] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:12:42,021] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:12:42,031] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:12:42,047] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:12:42,049] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:12:42,050] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:12:42,075] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:12:42,075] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:12:42,093] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:12:42,107] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:12:42,112] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:12:42,113] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:12:42,117] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:12:42,117] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:12:42,118] INFO Kafka startTimeMs: 1618657962113 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:12:42,119] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-17 04:12:42,228] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:13:33,012] INFO Creating topic updateProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:33,167] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(updateProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:33,207] INFO [Log partition=updateProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:33,213] INFO Created log for partition updateProfile-0 in /tmp/kafka-logs/updateProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:33,214] INFO [Partition updateProfile-0 broker=0] No checkpointed highwatermark is found for partition updateProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:13:33,215] INFO [Partition updateProfile-0 broker=0] Log loaded for partition updateProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:34,972] INFO Creating topic getProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:35,034] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:35,038] INFO [Log partition=getProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:35,039] INFO Created log for partition getProfile-0 in /tmp/kafka-logs/getProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:35,039] INFO [Partition getProfile-0 broker=0] No checkpointed highwatermark is found for partition getProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:13:35,040] INFO [Partition getProfile-0 broker=0] Log loaded for partition getProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:36,768] INFO Creating topic getFriends with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:36,825] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFriends-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:36,828] INFO [Log partition=getFriends-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:36,829] INFO Created log for partition getFriends-0 in /tmp/kafka-logs/getFriends-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:36,829] INFO [Partition getFriends-0 broker=0] No checkpointed highwatermark is found for partition getFriends-0 (kafka.cluster.Partition)
[2021-04-17 04:13:36,830] INFO [Partition getFriends-0 broker=0] Log loaded for partition getFriends-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:38,602] INFO Creating topic createGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:38,659] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(createGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:38,662] INFO [Log partition=createGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:38,663] INFO Created log for partition createGroup-0 in /tmp/kafka-logs/createGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:38,664] INFO [Partition createGroup-0 broker=0] No checkpointed highwatermark is found for partition createGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:13:38,664] INFO [Partition createGroup-0 broker=0] Log loaded for partition createGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:40,391] INFO Creating topic getRecentActivities with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:40,513] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getRecentActivities-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:40,522] INFO [Log partition=getRecentActivities-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:40,525] INFO Created log for partition getRecentActivities-0 in /tmp/kafka-logs/getRecentActivities-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:40,526] INFO [Partition getRecentActivities-0 broker=0] No checkpointed highwatermark is found for partition getRecentActivities-0 (kafka.cluster.Partition)
[2021-04-17 04:13:40,526] INFO [Partition getRecentActivities-0 broker=0] Log loaded for partition getRecentActivities-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:42,308] INFO Creating topic getGroupsDropdown with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:42,413] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupsDropdown-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:42,424] INFO [Log partition=getGroupsDropdown-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:42,426] INFO Created log for partition getGroupsDropdown-0 in /tmp/kafka-logs/getGroupsDropdown-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:42,427] INFO [Partition getGroupsDropdown-0 broker=0] No checkpointed highwatermark is found for partition getGroupsDropdown-0 (kafka.cluster.Partition)
[2021-04-17 04:13:42,427] INFO [Partition getGroupsDropdown-0 broker=0] Log loaded for partition getGroupsDropdown-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:44,266] INFO Creating topic getFilteredGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:44,339] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFilteredGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:44,349] INFO [Log partition=getFilteredGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:44,352] INFO Created log for partition getFilteredGroup-0 in /tmp/kafka-logs/getFilteredGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:44,354] INFO [Partition getFilteredGroup-0 broker=0] No checkpointed highwatermark is found for partition getFilteredGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:13:44,354] INFO [Partition getFilteredGroup-0 broker=0] Log loaded for partition getFilteredGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:46,275] INFO Creating topic getDashboardDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:46,339] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDashboardDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:46,349] INFO [Log partition=getDashboardDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:46,353] INFO Created log for partition getDashboardDetails-0 in /tmp/kafka-logs/getDashboardDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:46,354] INFO [Partition getDashboardDetails-0 broker=0] No checkpointed highwatermark is found for partition getDashboardDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:13:46,354] INFO [Partition getDashboardDetails-0 broker=0] Log loaded for partition getDashboardDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:48,309] INFO Creating topic getAllYouOwe with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:48,380] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouOwe-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:48,387] INFO [Log partition=getAllYouOwe-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:48,389] INFO Created log for partition getAllYouOwe-0 in /tmp/kafka-logs/getAllYouOwe-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:48,390] INFO [Partition getAllYouOwe-0 broker=0] No checkpointed highwatermark is found for partition getAllYouOwe-0 (kafka.cluster.Partition)
[2021-04-17 04:13:48,390] INFO [Partition getAllYouOwe-0 broker=0] Log loaded for partition getAllYouOwe-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:50,420] INFO Creating topic getAllYouAreOwed with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:50,512] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouAreOwed-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:50,519] INFO [Log partition=getAllYouAreOwed-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:50,522] INFO Created log for partition getAllYouAreOwed-0 in /tmp/kafka-logs/getAllYouAreOwed-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:50,523] INFO [Partition getAllYouAreOwed-0 broker=0] No checkpointed highwatermark is found for partition getAllYouAreOwed-0 (kafka.cluster.Partition)
[2021-04-17 04:13:50,523] INFO [Partition getAllYouAreOwed-0 broker=0] Log loaded for partition getAllYouAreOwed-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:52,265] INFO Creating topic settleUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:52,329] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(settleUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:52,336] INFO [Log partition=settleUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:52,339] INFO Created log for partition settleUp-0 in /tmp/kafka-logs/settleUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:52,340] INFO [Partition settleUp-0 broker=0] No checkpointed highwatermark is found for partition settleUp-0 (kafka.cluster.Partition)
[2021-04-17 04:13:52,340] INFO [Partition settleUp-0 broker=0] Log loaded for partition settleUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:54,347] INFO Creating topic getActiveGroups with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:54,404] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getActiveGroups-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:54,411] INFO [Log partition=getActiveGroups-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:54,414] INFO Created log for partition getActiveGroups-0 in /tmp/kafka-logs/getActiveGroups-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:54,415] INFO [Partition getActiveGroups-0 broker=0] No checkpointed highwatermark is found for partition getActiveGroups-0 (kafka.cluster.Partition)
[2021-04-17 04:13:54,415] INFO [Partition getActiveGroups-0 broker=0] Log loaded for partition getActiveGroups-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:56,244] INFO Creating topic getInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:56,300] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:56,302] INFO [Log partition=getInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:56,303] INFO Created log for partition getInvites-0 in /tmp/kafka-logs/getInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:56,304] INFO [Partition getInvites-0 broker=0] No checkpointed highwatermark is found for partition getInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:13:56,304] INFO [Partition getInvites-0 broker=0] Log loaded for partition getInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:13:58,167] INFO Creating topic acceptInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:13:58,254] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(acceptInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:13:58,261] INFO [Log partition=acceptInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:13:58,263] INFO Created log for partition acceptInvites-0 in /tmp/kafka-logs/acceptInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:13:58,281] INFO [Partition acceptInvites-0 broker=0] No checkpointed highwatermark is found for partition acceptInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:13:58,281] INFO [Partition acceptInvites-0 broker=0] Log loaded for partition acceptInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:14:00,147] INFO Creating topic getAllTransactions with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:14:00,220] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllTransactions-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:14:00,227] INFO [Log partition=getAllTransactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:14:00,229] INFO Created log for partition getAllTransactions-0 in /tmp/kafka-logs/getAllTransactions-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:14:00,230] INFO [Partition getAllTransactions-0 broker=0] No checkpointed highwatermark is found for partition getAllTransactions-0 (kafka.cluster.Partition)
[2021-04-17 04:14:00,230] INFO [Partition getAllTransactions-0 broker=0] Log loaded for partition getAllTransactions-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:14:02,198] INFO Creating topic getTransaction with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:14:02,362] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getTransaction-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:14:02,369] INFO [Log partition=getTransaction-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:14:02,371] INFO Created log for partition getTransaction-0 in /tmp/kafka-logs/getTransaction-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:14:02,372] INFO [Partition getTransaction-0 broker=0] No checkpointed highwatermark is found for partition getTransaction-0 (kafka.cluster.Partition)
[2021-04-17 04:14:02,372] INFO [Partition getTransaction-0 broker=0] Log loaded for partition getTransaction-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:14:04,334] INFO Creating topic getGroupDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:14:04,400] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:14:04,402] INFO [Log partition=getGroupDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:14:04,403] INFO Created log for partition getGroupDetails-0 in /tmp/kafka-logs/getGroupDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:14:04,403] INFO [Partition getGroupDetails-0 broker=0] No checkpointed highwatermark is found for partition getGroupDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:14:04,403] INFO [Partition getGroupDetails-0 broker=0] Log loaded for partition getGroupDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:14:06,279] INFO Creating topic getDues with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:14:06,357] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDues-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:14:06,363] INFO [Log partition=getDues-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:14:06,366] INFO Created log for partition getDues-0 in /tmp/kafka-logs/getDues-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:14:06,367] INFO [Partition getDues-0 broker=0] No checkpointed highwatermark is found for partition getDues-0 (kafka.cluster.Partition)
[2021-04-17 04:14:06,367] INFO [Partition getDues-0 broker=0] Log loaded for partition getDues-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:14:08,135] INFO Creating topic leaveGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:14:08,200] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(leaveGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:14:08,202] INFO [Log partition=leaveGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:14:08,203] INFO Created log for partition leaveGroup-0 in /tmp/kafka-logs/leaveGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:14:08,204] INFO [Partition leaveGroup-0 broker=0] No checkpointed highwatermark is found for partition leaveGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:14:08,204] INFO [Partition leaveGroup-0 broker=0] Log loaded for partition leaveGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:14:10,173] INFO Creating topic addNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:14:10,225] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:14:10,228] INFO [Log partition=addNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:14:10,229] INFO Created log for partition addNotes-0 in /tmp/kafka-logs/addNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:14:10,229] INFO [Partition addNotes-0 broker=0] No checkpointed highwatermark is found for partition addNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:14:10,229] INFO [Partition addNotes-0 broker=0] Log loaded for partition addNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:14:12,269] INFO Creating topic deleteNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:14:12,445] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(deleteNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:14:12,452] INFO [Log partition=deleteNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:14:12,455] INFO Created log for partition deleteNotes-0 in /tmp/kafka-logs/deleteNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:14:12,456] INFO [Partition deleteNotes-0 broker=0] No checkpointed highwatermark is found for partition deleteNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:14:12,456] INFO [Partition deleteNotes-0 broker=0] Log loaded for partition deleteNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:14:14,448] INFO Creating topic addExpense with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:14:14,503] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addExpense-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:14:14,509] INFO [Log partition=addExpense-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:14:14,510] INFO Created log for partition addExpense-0 in /tmp/kafka-logs/addExpense-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:14:14,511] INFO [Partition addExpense-0 broker=0] No checkpointed highwatermark is found for partition addExpense-0 (kafka.cluster.Partition)
[2021-04-17 04:14:14,511] INFO [Partition addExpense-0 broker=0] Log loaded for partition addExpense-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:14:16,424] INFO Creating topic login with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:14:16,503] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(login-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:14:16,509] INFO [Log partition=login-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:14:16,511] INFO Created log for partition login-0 in /tmp/kafka-logs/login-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:14:16,512] INFO [Partition login-0 broker=0] No checkpointed highwatermark is found for partition login-0 (kafka.cluster.Partition)
[2021-04-17 04:14:16,512] INFO [Partition login-0 broker=0] Log loaded for partition login-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:17:11,786] INFO Creating topic signUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:17:11,840] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(signUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:17:11,843] INFO [Log partition=signUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:17:11,844] INFO Created log for partition signUp-0 in /tmp/kafka-logs/signUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:17:11,845] INFO [Partition signUp-0 broker=0] No checkpointed highwatermark is found for partition signUp-0 (kafka.cluster.Partition)
[2021-04-17 04:17:11,845] INFO [Partition signUp-0 broker=0] Log loaded for partition signUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:18:00,684] INFO Creating topic response_topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:18:00,717] INFO [KafkaApi-0] Auto creation of topic response_topic with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2021-04-17 04:18:00,743] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(response_topic-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:18:00,745] INFO [Log partition=response_topic-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:18:00,746] INFO Created log for partition response_topic-0 in /tmp/kafka-logs/response_topic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:18:00,746] INFO [Partition response_topic-0 broker=0] No checkpointed highwatermark is found for partition response_topic-0 (kafka.cluster.Partition)
[2021-04-17 04:18:00,746] INFO [Partition response_topic-0 broker=0] Log loaded for partition response_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:25:17,152] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:25:17,155] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-17 04:25:17,157] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-17 04:25:17,191] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2021-04-17 04:25:17,199] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:25:17,200] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:25:17,200] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:25:17,201] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:25:17,208] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:25:17,209] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:25:17,212] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:25:17,219] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,400] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,400] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,401] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2021-04-17 04:25:17,403] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,517] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,517] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,520] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:25:17,522] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:25:17,523] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2021-04-17 04:25:17,523] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:25:17,523] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:25:17,523] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:25:17,525] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:25:17,526] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:25:17,527] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,692] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,692] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,692] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,892] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,892] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:17,893] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:25:17,895] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-17 04:25:17,895] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:25:17,896] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:25:17,896] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:25:17,897] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:25:17,900] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:25:17,901] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:25:17,901] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:25:17,901] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,095] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,095] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,096] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,131] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,131] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,132] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,331] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,331] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,332] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,531] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,531] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:25:18,571] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-17 04:25:18,571] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:25:18,572] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:25:18,572] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:25:18,572] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:25:18,574] INFO Shutting down. (kafka.log.LogManager)
[2021-04-17 04:25:18,604] INFO [ProducerStateManager partition=login-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,608] INFO [ProducerStateManager partition=getFilteredGroup-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,611] INFO [ProducerStateManager partition=response_topic-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,613] INFO [ProducerStateManager partition=getAllYouOwe-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,615] INFO [ProducerStateManager partition=getAllYouAreOwed-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,618] INFO [ProducerStateManager partition=getFriends-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,620] INFO [ProducerStateManager partition=getActiveGroups-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,622] INFO [ProducerStateManager partition=getInvites-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,623] INFO [ProducerStateManager partition=getRecentActivities-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,624] INFO [ProducerStateManager partition=getDashboardDetails-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,628] INFO [ProducerStateManager partition=getGroupsDropdown-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:25:18,719] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-17 04:25:18,732] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:25:18,733] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:25:18,733] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:25:18,735] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:25:18,855] INFO Session: 0x1002b0a59360000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:25:18,855] INFO EventThread shut down for session: 0x1002b0a59360000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:25:18,857] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:25:18,858] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:19,410] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:19,410] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:19,410] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:20,410] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:20,410] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:20,410] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:21,410] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:21,410] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:21,411] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:21,420] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:21,420] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:25:21,422] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-17 04:25:21,465] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-17 04:25:21,465] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:25:21,465] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:25:21,465] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:25:21,470] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2021-04-17 04:25:21,471] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:25:21,471] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-17 04:26:06,610] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:26:06,612] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:26:06,619] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:26:06,619] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:26:06,621] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:26:06,621] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:26:06,621] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:26:06,621] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-17 04:26:06,626] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-17 04:26:06,642] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:26:06,642] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:26:06,642] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:26:06,642] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:26:06,643] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-17 04:26:06,645] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:26:06,657] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,658] INFO Server environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,658] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,658] INFO Server environment:java.vendor=Ubuntu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,658] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,658] INFO Server environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:os.version=5.8.0-48-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:user.name=divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:user.home=/home/divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:os.memory.free=494MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,659] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,661] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,661] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,662] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:26:06,670] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-17 04:26:06,673] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:26:06,679] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:26:06,694] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-17 04:26:06,698] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:26:06,700] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:26:06,716] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-17 04:26:13,020] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-17 04:26:13,286] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-17 04:26:13,332] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:26:13,335] INFO starting (kafka.server.KafkaServer)
[2021-04-17 04:26:13,336] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-17 04:26:13,351] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:26:13,355] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,355] INFO Client environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,355] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,355] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,355] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,355] INFO Client environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,355] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,355] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,355] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,355] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,356] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,356] INFO Client environment:os.version=5.8.0-48-generic (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,356] INFO Client environment:user.name=divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,356] INFO Client environment:user.home=/home/divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,356] INFO Client environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,356] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,356] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,356] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,358] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@18ece7f4 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:26:13,361] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-17 04:26:13,366] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:26:13,369] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:26:13,375] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:26:13,379] INFO Socket connection established, initiating session, client: /127.0.0.1:52426, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:26:13,392] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-17 04:26:13,438] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002b16ccc60000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:26:13,440] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:26:13,701] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:26:13,723] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:26:13,724] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:26:13,890] INFO Cluster ID = U2mn5e71RPKnHfqfl7kkDA (kafka.server.KafkaServer)
[2021-04-17 04:26:13,892] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-04-17 04:26:13,953] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:26:13,961] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:26:13,996] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:26:13,997] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:26:13,999] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:26:14,000] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:26:14,024] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2021-04-17 04:26:14,030] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2021-04-17 04:26:14,032] INFO Attempting recovery for all logs in /tmp/kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2021-04-17 04:26:14,036] INFO Loaded 0 logs in 6ms. (kafka.log.LogManager)
[2021-04-17 04:26:14,070] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-17 04:26:14,072] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-17 04:26:14,459] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:26:14,461] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:26:14,465] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:26:14,468] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-17 04:26:14,505] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:26:14,538] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:26:14,538] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:26:14,539] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:26:14,539] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:26:14,555] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:26:14,555] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:26:14,592] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-17 04:26:14,635] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1618658774608,1618658774608,1,0,0,72104970962731008,220,0,24
 (kafka.zk.KafkaZkClient)
[2021-04-17 04:26:14,636] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://divyamohan-GL552VW:9092, czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2021-04-17 04:26:14,731] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:26:14,736] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:26:14,736] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:26:14,748] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2021-04-17 04:26:14,760] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:26:14,762] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:26:14,781] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:26:14,791] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:26:14,810] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:26:14,812] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:26:14,813] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:26:14,845] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:26:14,848] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:26:14,865] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:26:14,882] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:26:14,887] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:26:14,888] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:26:14,892] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:26:14,892] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:26:14,892] INFO Kafka startTimeMs: 1618658774888 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:26:14,895] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-17 04:26:15,057] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:26:40,258] INFO Creating topic updateProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:40,402] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(updateProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:40,448] INFO [Log partition=updateProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:40,454] INFO Created log for partition updateProfile-0 in /tmp/kafka-logs/updateProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:40,455] INFO [Partition updateProfile-0 broker=0] No checkpointed highwatermark is found for partition updateProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:26:40,456] INFO [Partition updateProfile-0 broker=0] Log loaded for partition updateProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:26:42,312] INFO Creating topic getProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:42,378] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:42,381] INFO [Log partition=getProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:42,382] INFO Created log for partition getProfile-0 in /tmp/kafka-logs/getProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:42,383] INFO [Partition getProfile-0 broker=0] No checkpointed highwatermark is found for partition getProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:26:42,383] INFO [Partition getProfile-0 broker=0] Log loaded for partition getProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:26:44,390] INFO Creating topic getFriends with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:44,444] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFriends-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:44,447] INFO [Log partition=getFriends-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:44,448] INFO Created log for partition getFriends-0 in /tmp/kafka-logs/getFriends-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:44,449] INFO [Partition getFriends-0 broker=0] No checkpointed highwatermark is found for partition getFriends-0 (kafka.cluster.Partition)
[2021-04-17 04:26:44,449] INFO [Partition getFriends-0 broker=0] Log loaded for partition getFriends-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:26:46,297] INFO Creating topic createGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:46,358] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(createGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:46,368] INFO [Log partition=createGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:46,371] INFO Created log for partition createGroup-0 in /tmp/kafka-logs/createGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:46,372] INFO [Partition createGroup-0 broker=0] No checkpointed highwatermark is found for partition createGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:26:46,372] INFO [Partition createGroup-0 broker=0] Log loaded for partition createGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:26:48,215] INFO Creating topic getRecentActivities with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:48,282] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getRecentActivities-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:48,288] INFO [Log partition=getRecentActivities-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:48,290] INFO Created log for partition getRecentActivities-0 in /tmp/kafka-logs/getRecentActivities-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:48,291] INFO [Partition getRecentActivities-0 broker=0] No checkpointed highwatermark is found for partition getRecentActivities-0 (kafka.cluster.Partition)
[2021-04-17 04:26:48,291] INFO [Partition getRecentActivities-0 broker=0] Log loaded for partition getRecentActivities-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:26:50,275] INFO Creating topic getGroupsDropdown with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:50,376] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupsDropdown-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:50,386] INFO [Log partition=getGroupsDropdown-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:50,388] INFO Created log for partition getGroupsDropdown-0 in /tmp/kafka-logs/getGroupsDropdown-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:50,388] INFO [Partition getGroupsDropdown-0 broker=0] No checkpointed highwatermark is found for partition getGroupsDropdown-0 (kafka.cluster.Partition)
[2021-04-17 04:26:50,389] INFO [Partition getGroupsDropdown-0 broker=0] Log loaded for partition getGroupsDropdown-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:26:52,389] INFO Creating topic getFilteredGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:52,510] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFilteredGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:52,521] INFO [Log partition=getFilteredGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:52,525] INFO Created log for partition getFilteredGroup-0 in /tmp/kafka-logs/getFilteredGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:52,527] INFO [Partition getFilteredGroup-0 broker=0] No checkpointed highwatermark is found for partition getFilteredGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:26:52,527] INFO [Partition getFilteredGroup-0 broker=0] Log loaded for partition getFilteredGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:26:54,572] INFO Creating topic getDashboardDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:54,638] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDashboardDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:54,644] INFO [Log partition=getDashboardDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:54,645] INFO Created log for partition getDashboardDetails-0 in /tmp/kafka-logs/getDashboardDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:54,646] INFO [Partition getDashboardDetails-0 broker=0] No checkpointed highwatermark is found for partition getDashboardDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:26:54,646] INFO [Partition getDashboardDetails-0 broker=0] Log loaded for partition getDashboardDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:26:56,895] INFO Creating topic getAllYouOwe with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:56,962] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouOwe-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:56,966] INFO [Log partition=getAllYouOwe-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:56,968] INFO Created log for partition getAllYouOwe-0 in /tmp/kafka-logs/getAllYouOwe-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:56,968] INFO [Partition getAllYouOwe-0 broker=0] No checkpointed highwatermark is found for partition getAllYouOwe-0 (kafka.cluster.Partition)
[2021-04-17 04:26:56,969] INFO [Partition getAllYouOwe-0 broker=0] Log loaded for partition getAllYouOwe-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:26:58,845] INFO Creating topic getAllYouAreOwed with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:26:58,949] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouAreOwed-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:26:58,956] INFO [Log partition=getAllYouAreOwed-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:26:58,958] INFO Created log for partition getAllYouAreOwed-0 in /tmp/kafka-logs/getAllYouAreOwed-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:26:58,959] INFO [Partition getAllYouAreOwed-0 broker=0] No checkpointed highwatermark is found for partition getAllYouAreOwed-0 (kafka.cluster.Partition)
[2021-04-17 04:26:58,959] INFO [Partition getAllYouAreOwed-0 broker=0] Log loaded for partition getAllYouAreOwed-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:00,855] INFO Creating topic settleUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:00,923] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(settleUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:00,928] INFO [Log partition=settleUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:00,929] INFO Created log for partition settleUp-0 in /tmp/kafka-logs/settleUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:00,930] INFO [Partition settleUp-0 broker=0] No checkpointed highwatermark is found for partition settleUp-0 (kafka.cluster.Partition)
[2021-04-17 04:27:00,930] INFO [Partition settleUp-0 broker=0] Log loaded for partition settleUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:02,711] INFO Creating topic getActiveGroups with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:02,781] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getActiveGroups-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:02,785] INFO [Log partition=getActiveGroups-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:02,786] INFO Created log for partition getActiveGroups-0 in /tmp/kafka-logs/getActiveGroups-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:02,787] INFO [Partition getActiveGroups-0 broker=0] No checkpointed highwatermark is found for partition getActiveGroups-0 (kafka.cluster.Partition)
[2021-04-17 04:27:02,787] INFO [Partition getActiveGroups-0 broker=0] Log loaded for partition getActiveGroups-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:04,390] INFO Creating topic getInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:04,457] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:04,464] INFO [Log partition=getInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:04,466] INFO Created log for partition getInvites-0 in /tmp/kafka-logs/getInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:04,467] INFO [Partition getInvites-0 broker=0] No checkpointed highwatermark is found for partition getInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:27:04,467] INFO [Partition getInvites-0 broker=0] Log loaded for partition getInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:06,557] INFO Creating topic acceptInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:06,642] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(acceptInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:06,649] INFO [Log partition=acceptInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:06,651] INFO Created log for partition acceptInvites-0 in /tmp/kafka-logs/acceptInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:06,652] INFO [Partition acceptInvites-0 broker=0] No checkpointed highwatermark is found for partition acceptInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:27:06,652] INFO [Partition acceptInvites-0 broker=0] Log loaded for partition acceptInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:08,522] INFO Creating topic getAllTransactions with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:08,592] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllTransactions-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:08,601] INFO [Log partition=getAllTransactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:08,604] INFO Created log for partition getAllTransactions-0 in /tmp/kafka-logs/getAllTransactions-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:08,606] INFO [Partition getAllTransactions-0 broker=0] No checkpointed highwatermark is found for partition getAllTransactions-0 (kafka.cluster.Partition)
[2021-04-17 04:27:08,606] INFO [Partition getAllTransactions-0 broker=0] Log loaded for partition getAllTransactions-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:10,302] INFO Creating topic getTransaction with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:10,367] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getTransaction-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:10,373] INFO [Log partition=getTransaction-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:10,376] INFO Created log for partition getTransaction-0 in /tmp/kafka-logs/getTransaction-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:10,377] INFO [Partition getTransaction-0 broker=0] No checkpointed highwatermark is found for partition getTransaction-0 (kafka.cluster.Partition)
[2021-04-17 04:27:10,377] INFO [Partition getTransaction-0 broker=0] Log loaded for partition getTransaction-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:12,450] INFO Creating topic getGroupDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:12,514] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:12,517] INFO [Log partition=getGroupDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:12,519] INFO Created log for partition getGroupDetails-0 in /tmp/kafka-logs/getGroupDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:12,519] INFO [Partition getGroupDetails-0 broker=0] No checkpointed highwatermark is found for partition getGroupDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:27:12,519] INFO [Partition getGroupDetails-0 broker=0] Log loaded for partition getGroupDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:14,336] INFO Creating topic getDues with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:14,429] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDues-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:14,435] INFO [Log partition=getDues-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:14,437] INFO Created log for partition getDues-0 in /tmp/kafka-logs/getDues-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:14,438] INFO [Partition getDues-0 broker=0] No checkpointed highwatermark is found for partition getDues-0 (kafka.cluster.Partition)
[2021-04-17 04:27:14,438] INFO [Partition getDues-0 broker=0] Log loaded for partition getDues-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:16,210] INFO Creating topic leaveGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:16,272] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(leaveGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:16,275] INFO [Log partition=leaveGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:16,276] INFO Created log for partition leaveGroup-0 in /tmp/kafka-logs/leaveGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:16,277] INFO [Partition leaveGroup-0 broker=0] No checkpointed highwatermark is found for partition leaveGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:27:16,277] INFO [Partition leaveGroup-0 broker=0] Log loaded for partition leaveGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:18,038] INFO Creating topic addNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:18,183] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:18,190] INFO [Log partition=addNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:18,192] INFO Created log for partition addNotes-0 in /tmp/kafka-logs/addNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:18,193] INFO [Partition addNotes-0 broker=0] No checkpointed highwatermark is found for partition addNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:27:18,193] INFO [Partition addNotes-0 broker=0] Log loaded for partition addNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:20,110] INFO Creating topic deleteNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:20,174] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(deleteNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:20,179] INFO [Log partition=deleteNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:20,180] INFO Created log for partition deleteNotes-0 in /tmp/kafka-logs/deleteNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:20,181] INFO [Partition deleteNotes-0 broker=0] No checkpointed highwatermark is found for partition deleteNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:27:20,181] INFO [Partition deleteNotes-0 broker=0] Log loaded for partition deleteNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:21,968] INFO Creating topic addExpense with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:22,032] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addExpense-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:22,037] INFO [Log partition=addExpense-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:22,038] INFO Created log for partition addExpense-0 in /tmp/kafka-logs/addExpense-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:22,039] INFO [Partition addExpense-0 broker=0] No checkpointed highwatermark is found for partition addExpense-0 (kafka.cluster.Partition)
[2021-04-17 04:27:22,039] INFO [Partition addExpense-0 broker=0] Log loaded for partition addExpense-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:23,778] INFO Creating topic login with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:23,884] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(login-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:23,891] INFO [Log partition=login-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:23,893] INFO Created log for partition login-0 in /tmp/kafka-logs/login-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:23,894] INFO [Partition login-0 broker=0] No checkpointed highwatermark is found for partition login-0 (kafka.cluster.Partition)
[2021-04-17 04:27:23,894] INFO [Partition login-0 broker=0] Log loaded for partition login-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:27:45,842] INFO Creating topic signUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:27:45,900] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(signUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:27:45,903] INFO [Log partition=signUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:27:45,904] INFO Created log for partition signUp-0 in /tmp/kafka-logs/signUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:27:45,904] INFO [Partition signUp-0 broker=0] No checkpointed highwatermark is found for partition signUp-0 (kafka.cluster.Partition)
[2021-04-17 04:27:45,904] INFO [Partition signUp-0 broker=0] Log loaded for partition signUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:28:21,417] INFO Creating topic response_topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:28:21,444] INFO [KafkaApi-0] Auto creation of topic response_topic with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2021-04-17 04:28:21,469] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(response_topic-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:28:21,472] INFO [Log partition=response_topic-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:28:21,472] INFO Created log for partition response_topic-0 in /tmp/kafka-logs/response_topic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:28:21,473] INFO [Partition response_topic-0 broker=0] No checkpointed highwatermark is found for partition response_topic-0 (kafka.cluster.Partition)
[2021-04-17 04:28:21,473] INFO [Partition response_topic-0 broker=0] Log loaded for partition response_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:10,491] ERROR Error while writing to checkpoint file /tmp/kafka-logs/replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.io.FileNotFoundException: /tmp/kafka-logs/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:187)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:94)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:92)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:67)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1769)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1768)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:553)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:551)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:920)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:890)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1768)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:292)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2021-04-17 04:36:10,516] WARN [ReplicaManager broker=0] Stopping serving replicas in dir /tmp/kafka-logs (kafka.server.ReplicaManager)
[2021-04-17 04:36:10,517] ERROR [ReplicaManager broker=0] Error while writing to highwatermark file in directory /tmp/kafka-logs (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /tmp/kafka-logs/replication-offset-checkpoint
Caused by: java.io.FileNotFoundException: /tmp/kafka-logs/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:187)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:94)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:92)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:67)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1769)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1768)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:553)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:551)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:920)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:890)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1768)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:292)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2021-04-17 04:36:10,519] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(createGroup-0, getAllYouOwe-0, getDues-0, getGroupDetails-0, response_topic-0, updateProfile-0, getAllTransactions-0, getGroupsDropdown-0, getDashboardDetails-0, getFriends-0, addNotes-0, acceptInvites-0, getAllYouAreOwed-0, signUp-0, leaveGroup-0, getTransaction-0, getFilteredGroup-0, deleteNotes-0, getProfile-0, addExpense-0, getInvites-0, login-0, getActiveGroups-0, getRecentActivities-0, settleUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:36:10,520] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions HashSet(createGroup-0, getAllYouOwe-0, getDues-0, getGroupDetails-0, response_topic-0, updateProfile-0, getAllTransactions-0, getGroupsDropdown-0, getDashboardDetails-0, getFriends-0, addNotes-0, acceptInvites-0, getAllYouAreOwed-0, signUp-0, leaveGroup-0, getTransaction-0, getFilteredGroup-0, deleteNotes-0, getProfile-0, addExpense-0, getInvites-0, login-0, getActiveGroups-0, getRecentActivities-0, settleUp-0) (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:36:10,536] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions createGroup-0,getAllYouOwe-0,getDues-0,getGroupDetails-0,response_topic-0,updateProfile-0,getAllTransactions-0,getGroupsDropdown-0,getDashboardDetails-0,getFriends-0,addNotes-0,acceptInvites-0,getAllYouAreOwed-0,signUp-0,leaveGroup-0,getTransaction-0,getFilteredGroup-0,deleteNotes-0,getProfile-0,addExpense-0,getInvites-0,login-0,getActiveGroups-0,getRecentActivities-0,settleUp-0 and stopped moving logs for partitions  because they are in the failed log directory /tmp/kafka-logs. (kafka.server.ReplicaManager)
[2021-04-17 04:36:10,537] WARN Stopping serving logs in dir /tmp/kafka-logs (kafka.log.LogManager)
[2021-04-17 04:36:10,540] ERROR Shutdown broker because all log dirs in /tmp/kafka-logs have failed (kafka.log.LogManager)
[2021-04-17 04:36:10,907] WARN Unable to read additional data from client sessionid 0x1002b16ccc60000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2021-04-17 04:36:26,201] INFO Expiring session 0x1002b16ccc60000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:36:47,434] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-17 04:36:47,689] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-17 04:36:47,733] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:36:47,737] INFO starting (kafka.server.KafkaServer)
[2021-04-17 04:36:47,738] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-17 04:36:47,752] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:36:47,756] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,756] INFO Client environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,756] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,756] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,756] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,756] INFO Client environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:os.version=5.8.0-48-generic (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:user.name=divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:user.home=/home/divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,757] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,759] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@18ece7f4 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:36:47,763] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-17 04:36:47,768] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:36:47,772] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:36:47,776] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:36:47,781] INFO Socket connection established, initiating session, client: /127.0.0.1:58064, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:36:47,803] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002b16ccc60001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:36:47,810] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:36:47,992] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:36:48,184] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:36:48,187] INFO Cluster ID = U2mn5e71RPKnHfqfl7kkDA (kafka.server.KafkaServer)
[2021-04-17 04:36:48,188] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-04-17 04:36:48,233] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:36:48,240] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:36:48,271] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:36:48,272] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:36:48,273] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:36:48,274] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:36:48,327] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2021-04-17 04:36:48,333] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2021-04-17 04:36:48,335] INFO Attempting recovery for all logs in /tmp/kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2021-04-17 04:36:48,339] INFO Loaded 0 logs in 6ms. (kafka.log.LogManager)
[2021-04-17 04:36:48,357] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-17 04:36:48,359] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-17 04:36:48,745] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:36:48,748] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:36:48,750] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:36:48,755] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-17 04:36:48,795] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:36:48,829] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:36:48,830] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:36:48,831] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:36:48,831] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:36:48,849] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:36:48,849] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:36:48,900] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-17 04:36:48,918] INFO Stat of the created znode at /brokers/ids/0 is: 365,365,1618659408910,1618659408910,1,0,0,72104970962731009,220,0,365
 (kafka.zk.KafkaZkClient)
[2021-04-17 04:36:48,919] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://divyamohan-GL552VW:9092, czxid (broker epoch): 365 (kafka.zk.KafkaZkClient)
[2021-04-17 04:36:49,024] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:36:49,028] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:36:49,029] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:36:49,054] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:36:49,056] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:36:49,074] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:36:49,093] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:36:49,095] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:36:49,095] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:36:49,125] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:36:49,142] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:36:49,244] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:36:49,249] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:36:49,250] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:36:49,255] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:36:49,255] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:36:49,255] INFO Kafka startTimeMs: 1618659409250 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:36:49,257] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-17 04:36:49,351] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:36:49,362] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(createGroup-0, getAllYouOwe-0, getDues-0, getGroupDetails-0, response_topic-0, updateProfile-0, getAllTransactions-0, getGroupsDropdown-0, getDashboardDetails-0, getFriends-0, addNotes-0, acceptInvites-0, getAllYouAreOwed-0, signUp-0, leaveGroup-0, getTransaction-0, getFilteredGroup-0, deleteNotes-0, getProfile-0, addExpense-0, getInvites-0, login-0, getActiveGroups-0, getRecentActivities-0, settleUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:36:49,436] INFO [Log partition=getFilteredGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,445] INFO Created log for partition getFilteredGroup-0 in /tmp/kafka-logs/getFilteredGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,446] INFO [Partition getFilteredGroup-0 broker=0] No checkpointed highwatermark is found for partition getFilteredGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,447] INFO [Partition getFilteredGroup-0 broker=0] Log loaded for partition getFilteredGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,488] INFO [Log partition=getActiveGroups-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,489] INFO Created log for partition getActiveGroups-0 in /tmp/kafka-logs/getActiveGroups-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,489] INFO [Partition getActiveGroups-0 broker=0] No checkpointed highwatermark is found for partition getActiveGroups-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,489] INFO [Partition getActiveGroups-0 broker=0] Log loaded for partition getActiveGroups-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,525] INFO [Log partition=createGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,526] INFO Created log for partition createGroup-0 in /tmp/kafka-logs/createGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,526] INFO [Partition createGroup-0 broker=0] No checkpointed highwatermark is found for partition createGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,526] INFO [Partition createGroup-0 broker=0] Log loaded for partition createGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,551] INFO [Log partition=leaveGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,552] INFO Created log for partition leaveGroup-0 in /tmp/kafka-logs/leaveGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,552] INFO [Partition leaveGroup-0 broker=0] No checkpointed highwatermark is found for partition leaveGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,552] INFO [Partition leaveGroup-0 broker=0] Log loaded for partition leaveGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,576] INFO [Log partition=getAllYouAreOwed-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,577] INFO Created log for partition getAllYouAreOwed-0 in /tmp/kafka-logs/getAllYouAreOwed-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,577] INFO [Partition getAllYouAreOwed-0 broker=0] No checkpointed highwatermark is found for partition getAllYouAreOwed-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,577] INFO [Partition getAllYouAreOwed-0 broker=0] Log loaded for partition getAllYouAreOwed-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,602] INFO [Log partition=deleteNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,603] INFO Created log for partition deleteNotes-0 in /tmp/kafka-logs/deleteNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,603] INFO [Partition deleteNotes-0 broker=0] No checkpointed highwatermark is found for partition deleteNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,603] INFO [Partition deleteNotes-0 broker=0] Log loaded for partition deleteNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,636] INFO [Log partition=acceptInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,637] INFO Created log for partition acceptInvites-0 in /tmp/kafka-logs/acceptInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,637] INFO [Partition acceptInvites-0 broker=0] No checkpointed highwatermark is found for partition acceptInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,637] INFO [Partition acceptInvites-0 broker=0] Log loaded for partition acceptInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,662] INFO [Log partition=getProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,663] INFO Created log for partition getProfile-0 in /tmp/kafka-logs/getProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,663] INFO [Partition getProfile-0 broker=0] No checkpointed highwatermark is found for partition getProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,663] INFO [Partition getProfile-0 broker=0] Log loaded for partition getProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,695] INFO [Log partition=getRecentActivities-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,696] INFO Created log for partition getRecentActivities-0 in /tmp/kafka-logs/getRecentActivities-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,696] INFO [Partition getRecentActivities-0 broker=0] No checkpointed highwatermark is found for partition getRecentActivities-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,696] INFO [Partition getRecentActivities-0 broker=0] Log loaded for partition getRecentActivities-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,721] INFO [Log partition=response_topic-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,722] INFO Created log for partition response_topic-0 in /tmp/kafka-logs/response_topic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,722] INFO [Partition response_topic-0 broker=0] No checkpointed highwatermark is found for partition response_topic-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,722] INFO [Partition response_topic-0 broker=0] Log loaded for partition response_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,749] INFO [Log partition=getInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,750] INFO Created log for partition getInvites-0 in /tmp/kafka-logs/getInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,751] INFO [Partition getInvites-0 broker=0] No checkpointed highwatermark is found for partition getInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,751] INFO [Partition getInvites-0 broker=0] Log loaded for partition getInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,774] INFO [Log partition=addNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,776] INFO Created log for partition addNotes-0 in /tmp/kafka-logs/addNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,777] INFO [Partition addNotes-0 broker=0] No checkpointed highwatermark is found for partition addNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,777] INFO [Partition addNotes-0 broker=0] Log loaded for partition addNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,817] INFO [Log partition=updateProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,818] INFO Created log for partition updateProfile-0 in /tmp/kafka-logs/updateProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,818] INFO [Partition updateProfile-0 broker=0] No checkpointed highwatermark is found for partition updateProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,819] INFO [Partition updateProfile-0 broker=0] Log loaded for partition updateProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,849] INFO [Log partition=getAllTransactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,850] INFO Created log for partition getAllTransactions-0 in /tmp/kafka-logs/getAllTransactions-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,850] INFO [Partition getAllTransactions-0 broker=0] No checkpointed highwatermark is found for partition getAllTransactions-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,851] INFO [Partition getAllTransactions-0 broker=0] Log loaded for partition getAllTransactions-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,883] INFO [Log partition=signUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,885] INFO Created log for partition signUp-0 in /tmp/kafka-logs/signUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,885] INFO [Partition signUp-0 broker=0] No checkpointed highwatermark is found for partition signUp-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,885] INFO [Partition signUp-0 broker=0] Log loaded for partition signUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,908] INFO [Log partition=addExpense-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,910] INFO Created log for partition addExpense-0 in /tmp/kafka-logs/addExpense-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,910] INFO [Partition addExpense-0 broker=0] No checkpointed highwatermark is found for partition addExpense-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,910] INFO [Partition addExpense-0 broker=0] Log loaded for partition addExpense-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,942] INFO [Log partition=getAllYouOwe-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,943] INFO Created log for partition getAllYouOwe-0 in /tmp/kafka-logs/getAllYouOwe-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,943] INFO [Partition getAllYouOwe-0 broker=0] No checkpointed highwatermark is found for partition getAllYouOwe-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,943] INFO [Partition getAllYouOwe-0 broker=0] Log loaded for partition getAllYouOwe-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,968] INFO [Log partition=settleUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:49,968] INFO Created log for partition settleUp-0 in /tmp/kafka-logs/settleUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:49,969] INFO [Partition settleUp-0 broker=0] No checkpointed highwatermark is found for partition settleUp-0 (kafka.cluster.Partition)
[2021-04-17 04:36:49,969] INFO [Partition settleUp-0 broker=0] Log loaded for partition settleUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,001] INFO [Log partition=getGroupsDropdown-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:50,002] INFO Created log for partition getGroupsDropdown-0 in /tmp/kafka-logs/getGroupsDropdown-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:50,002] INFO [Partition getGroupsDropdown-0 broker=0] No checkpointed highwatermark is found for partition getGroupsDropdown-0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,002] INFO [Partition getGroupsDropdown-0 broker=0] Log loaded for partition getGroupsDropdown-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,026] INFO [Log partition=getDues-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:50,027] INFO Created log for partition getDues-0 in /tmp/kafka-logs/getDues-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:50,027] INFO [Partition getDues-0 broker=0] No checkpointed highwatermark is found for partition getDues-0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,027] INFO [Partition getDues-0 broker=0] Log loaded for partition getDues-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,060] INFO [Log partition=login-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:50,061] INFO Created log for partition login-0 in /tmp/kafka-logs/login-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:50,061] INFO [Partition login-0 broker=0] No checkpointed highwatermark is found for partition login-0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,061] INFO [Partition login-0 broker=0] Log loaded for partition login-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,094] INFO [Log partition=getGroupDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:50,095] INFO Created log for partition getGroupDetails-0 in /tmp/kafka-logs/getGroupDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:50,095] INFO [Partition getGroupDetails-0 broker=0] No checkpointed highwatermark is found for partition getGroupDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,095] INFO [Partition getGroupDetails-0 broker=0] Log loaded for partition getGroupDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,127] INFO [Log partition=getTransaction-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:50,128] INFO Created log for partition getTransaction-0 in /tmp/kafka-logs/getTransaction-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:50,128] INFO [Partition getTransaction-0 broker=0] No checkpointed highwatermark is found for partition getTransaction-0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,128] INFO [Partition getTransaction-0 broker=0] Log loaded for partition getTransaction-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,162] INFO [Log partition=getDashboardDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:50,163] INFO Created log for partition getDashboardDetails-0 in /tmp/kafka-logs/getDashboardDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:50,163] INFO [Partition getDashboardDetails-0 broker=0] No checkpointed highwatermark is found for partition getDashboardDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,163] INFO [Partition getDashboardDetails-0 broker=0] Log loaded for partition getDashboardDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,196] INFO [Log partition=getFriends-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:36:50,197] INFO Created log for partition getFriends-0 in /tmp/kafka-logs/getFriends-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:36:50,197] INFO [Partition getFriends-0 broker=0] No checkpointed highwatermark is found for partition getFriends-0 (kafka.cluster.Partition)
[2021-04-17 04:36:50,197] INFO [Partition getFriends-0 broker=0] Log loaded for partition getFriends-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:41:02,562] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:41:02,567] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-17 04:41:02,569] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-17 04:41:02,583] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2021-04-17 04:41:02,587] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:41:02,588] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:41:02,588] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:41:02,589] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:41:02,595] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:41:02,596] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:41:02,598] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:41:02,600] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,645] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,645] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,646] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2021-04-17 04:41:02,646] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,742] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,742] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,745] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:41:02,747] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 1000 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:41:02,749] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2021-04-17 04:41:02,749] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:41:02,750] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:41:02,750] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:41:02,751] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:41:02,752] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:41:02,753] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,949] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,949] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,950] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,962] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,962] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:02,963] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:41:02,965] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-17 04:41:02,966] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:41:02,966] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:41:02,966] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:41:02,968] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:41:02,972] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:41:02,973] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:41:02,974] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:41:02,974] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,008] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,008] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,010] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,159] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,159] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,160] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,353] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,353] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,354] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,550] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,550] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:03,579] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-17 04:41:03,580] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:41:03,582] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:41:03,581] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:41:03,582] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:41:03,584] INFO Shutting down. (kafka.log.LogManager)
[2021-04-17 04:41:03,617] INFO [ProducerStateManager partition=login-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2021-04-17 04:41:03,623] INFO [ProducerStateManager partition=response_topic-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2021-04-17 04:41:03,719] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-17 04:41:03,734] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:41:03,734] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:41:03,734] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:41:03,736] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:41:03,854] INFO Session: 0x1002b16ccc60001 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:03,854] INFO EventThread shut down for session: 0x1002b16ccc60001 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:41:03,856] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:41:03,857] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:04,302] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:04,302] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:04,303] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:04,312] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:04,312] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:04,313] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:05,307] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:05,307] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:05,307] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:06,307] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:06,307] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:06,309] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-17 04:41:06,329] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-17 04:41:06,330] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:41:06,330] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:41:06,330] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:41:06,333] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2021-04-17 04:41:06,333] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:41:06,333] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-17 04:41:23,251] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:41:23,253] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:41:23,257] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:41:23,257] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:41:23,259] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:41:23,259] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:41:23,259] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:41:23,259] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-17 04:41:23,262] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-17 04:41:23,273] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:41:23,273] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:41:23,274] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:41:23,274] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:41:23,274] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-17 04:41:23,276] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:41:23,285] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,285] INFO Server environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:java.vendor=Ubuntu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,286] INFO Server environment:os.version=5.8.0-48-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,287] INFO Server environment:user.name=divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,287] INFO Server environment:user.home=/home/divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,287] INFO Server environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,287] INFO Server environment:os.memory.free=494MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,287] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,287] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,288] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,288] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,288] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:41:23,295] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-17 04:41:23,298] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:41:23,302] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:41:23,315] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-17 04:41:23,319] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:41:23,322] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:41:23,338] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-17 04:41:27,853] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-17 04:41:28,100] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-17 04:41:28,143] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:41:28,146] INFO starting (kafka.server.KafkaServer)
[2021-04-17 04:41:28,147] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-17 04:41:28,162] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:41:28,166] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,166] INFO Client environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,166] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,166] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,166] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:os.version=5.8.0-48-generic (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:user.name=divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:user.home=/home/divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,167] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,169] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@18ece7f4 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:41:28,172] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-17 04:41:28,177] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:41:28,180] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:41:28,183] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:41:28,187] INFO Socket connection established, initiating session, client: /127.0.0.1:60742, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:41:28,199] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-17 04:41:28,329] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002b24c9540000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:41:28,336] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:41:28,612] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:41:28,646] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:41:28,647] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:41:28,809] INFO Cluster ID = iDXtBGr9TK-2twRbNI1l7g (kafka.server.KafkaServer)
[2021-04-17 04:41:28,812] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-04-17 04:41:28,866] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:41:28,875] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:41:28,910] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:28,911] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:28,912] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:28,914] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:41:28,938] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2021-04-17 04:41:28,943] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2021-04-17 04:41:28,945] INFO Attempting recovery for all logs in /tmp/kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2021-04-17 04:41:28,949] INFO Loaded 0 logs in 5ms. (kafka.log.LogManager)
[2021-04-17 04:41:28,982] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-17 04:41:28,984] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-17 04:41:29,355] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:41:29,357] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:41:29,360] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:41:29,363] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-17 04:41:29,402] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:41:29,432] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:29,433] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:29,434] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:29,435] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:29,447] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:41:29,448] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:41:29,489] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-17 04:41:29,514] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1618659689504,1618659689504,1,0,0,72105031034470400,220,0,24
 (kafka.zk.KafkaZkClient)
[2021-04-17 04:41:29,516] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://divyamohan-GL552VW:9092, czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2021-04-17 04:41:29,608] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:29,611] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:29,612] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:29,625] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2021-04-17 04:41:29,638] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:41:29,640] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:41:29,650] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:41:29,660] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:41:29,677] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:41:29,683] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:41:29,683] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:41:29,703] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:41:29,707] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:41:29,725] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:41:29,735] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:41:29,740] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:41:29,741] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:41:29,751] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:41:29,752] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:41:29,752] INFO Kafka startTimeMs: 1618659689742 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:41:29,753] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-17 04:41:29,850] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:41:55,834] INFO Creating topic updateProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:41:55,959] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(updateProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:41:56,006] INFO [Log partition=updateProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:41:56,013] INFO Created log for partition updateProfile-0 in /tmp/kafka-logs/updateProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:41:56,014] INFO [Partition updateProfile-0 broker=0] No checkpointed highwatermark is found for partition updateProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:41:56,014] INFO [Partition updateProfile-0 broker=0] Log loaded for partition updateProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:41:57,746] INFO Creating topic getProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:41:57,816] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:41:57,820] INFO [Log partition=getProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:41:57,822] INFO Created log for partition getProfile-0 in /tmp/kafka-logs/getProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:41:57,822] INFO [Partition getProfile-0 broker=0] No checkpointed highwatermark is found for partition getProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:41:57,823] INFO [Partition getProfile-0 broker=0] Log loaded for partition getProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:41:59,651] INFO Creating topic getFriends with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:41:59,762] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFriends-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:41:59,767] INFO [Log partition=getFriends-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:41:59,769] INFO Created log for partition getFriends-0 in /tmp/kafka-logs/getFriends-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:41:59,770] INFO [Partition getFriends-0 broker=0] No checkpointed highwatermark is found for partition getFriends-0 (kafka.cluster.Partition)
[2021-04-17 04:41:59,770] INFO [Partition getFriends-0 broker=0] Log loaded for partition getFriends-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:01,506] INFO Creating topic createGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:01,582] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(createGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:01,586] INFO [Log partition=createGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:01,587] INFO Created log for partition createGroup-0 in /tmp/kafka-logs/createGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:01,587] INFO [Partition createGroup-0 broker=0] No checkpointed highwatermark is found for partition createGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:42:01,587] INFO [Partition createGroup-0 broker=0] Log loaded for partition createGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:03,370] INFO Creating topic getRecentActivities with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:03,446] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getRecentActivities-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:03,453] INFO [Log partition=getRecentActivities-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:03,456] INFO Created log for partition getRecentActivities-0 in /tmp/kafka-logs/getRecentActivities-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:03,457] INFO [Partition getRecentActivities-0 broker=0] No checkpointed highwatermark is found for partition getRecentActivities-0 (kafka.cluster.Partition)
[2021-04-17 04:42:03,457] INFO [Partition getRecentActivities-0 broker=0] Log loaded for partition getRecentActivities-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:05,386] INFO Creating topic getGroupsDropdown with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:05,475] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupsDropdown-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:05,481] INFO [Log partition=getGroupsDropdown-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:05,483] INFO Created log for partition getGroupsDropdown-0 in /tmp/kafka-logs/getGroupsDropdown-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:05,483] INFO [Partition getGroupsDropdown-0 broker=0] No checkpointed highwatermark is found for partition getGroupsDropdown-0 (kafka.cluster.Partition)
[2021-04-17 04:42:05,484] INFO [Partition getGroupsDropdown-0 broker=0] Log loaded for partition getGroupsDropdown-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:07,479] INFO Creating topic getFilteredGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:07,546] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFilteredGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:07,556] INFO [Log partition=getFilteredGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:07,559] INFO Created log for partition getFilteredGroup-0 in /tmp/kafka-logs/getFilteredGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:07,560] INFO [Partition getFilteredGroup-0 broker=0] No checkpointed highwatermark is found for partition getFilteredGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:42:07,560] INFO [Partition getFilteredGroup-0 broker=0] Log loaded for partition getFilteredGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:09,526] INFO Creating topic getDashboardDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:09,592] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDashboardDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:09,598] INFO [Log partition=getDashboardDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:09,599] INFO Created log for partition getDashboardDetails-0 in /tmp/kafka-logs/getDashboardDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:09,600] INFO [Partition getDashboardDetails-0 broker=0] No checkpointed highwatermark is found for partition getDashboardDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:42:09,600] INFO [Partition getDashboardDetails-0 broker=0] Log loaded for partition getDashboardDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:11,502] INFO Creating topic getAllYouOwe with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:11,565] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouOwe-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:11,573] INFO [Log partition=getAllYouOwe-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:11,578] INFO Created log for partition getAllYouOwe-0 in /tmp/kafka-logs/getAllYouOwe-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:11,579] INFO [Partition getAllYouOwe-0 broker=0] No checkpointed highwatermark is found for partition getAllYouOwe-0 (kafka.cluster.Partition)
[2021-04-17 04:42:11,579] INFO [Partition getAllYouOwe-0 broker=0] Log loaded for partition getAllYouOwe-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:13,695] INFO Creating topic getAllYouAreOwed with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:13,773] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouAreOwed-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:13,776] INFO [Log partition=getAllYouAreOwed-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:13,777] INFO Created log for partition getAllYouAreOwed-0 in /tmp/kafka-logs/getAllYouAreOwed-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:13,778] INFO [Partition getAllYouAreOwed-0 broker=0] No checkpointed highwatermark is found for partition getAllYouAreOwed-0 (kafka.cluster.Partition)
[2021-04-17 04:42:13,778] INFO [Partition getAllYouAreOwed-0 broker=0] Log loaded for partition getAllYouAreOwed-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:15,981] INFO Creating topic settleUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:16,192] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(settleUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:16,195] INFO [Log partition=settleUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:16,196] INFO Created log for partition settleUp-0 in /tmp/kafka-logs/settleUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:16,197] INFO [Partition settleUp-0 broker=0] No checkpointed highwatermark is found for partition settleUp-0 (kafka.cluster.Partition)
[2021-04-17 04:42:16,197] INFO [Partition settleUp-0 broker=0] Log loaded for partition settleUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:18,199] INFO Creating topic getActiveGroups with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:18,258] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getActiveGroups-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:18,261] INFO [Log partition=getActiveGroups-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:18,262] INFO Created log for partition getActiveGroups-0 in /tmp/kafka-logs/getActiveGroups-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:18,263] INFO [Partition getActiveGroups-0 broker=0] No checkpointed highwatermark is found for partition getActiveGroups-0 (kafka.cluster.Partition)
[2021-04-17 04:42:18,263] INFO [Partition getActiveGroups-0 broker=0] Log loaded for partition getActiveGroups-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:20,291] INFO Creating topic getInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:20,362] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:20,369] INFO [Log partition=getInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:20,371] INFO Created log for partition getInvites-0 in /tmp/kafka-logs/getInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:20,371] INFO [Partition getInvites-0 broker=0] No checkpointed highwatermark is found for partition getInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:42:20,372] INFO [Partition getInvites-0 broker=0] Log loaded for partition getInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:22,277] INFO Creating topic acceptInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:22,363] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(acceptInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:22,369] INFO [Log partition=acceptInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:22,371] INFO Created log for partition acceptInvites-0 in /tmp/kafka-logs/acceptInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:22,372] INFO [Partition acceptInvites-0 broker=0] No checkpointed highwatermark is found for partition acceptInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:42:22,373] INFO [Partition acceptInvites-0 broker=0] Log loaded for partition acceptInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:24,359] INFO Creating topic getAllTransactions with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:24,425] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllTransactions-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:24,427] INFO [Log partition=getAllTransactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:24,428] INFO Created log for partition getAllTransactions-0 in /tmp/kafka-logs/getAllTransactions-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:24,429] INFO [Partition getAllTransactions-0 broker=0] No checkpointed highwatermark is found for partition getAllTransactions-0 (kafka.cluster.Partition)
[2021-04-17 04:42:24,429] INFO [Partition getAllTransactions-0 broker=0] Log loaded for partition getAllTransactions-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:26,269] INFO Creating topic getTransaction with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:26,337] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getTransaction-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:26,345] INFO [Log partition=getTransaction-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:26,349] INFO Created log for partition getTransaction-0 in /tmp/kafka-logs/getTransaction-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:26,350] INFO [Partition getTransaction-0 broker=0] No checkpointed highwatermark is found for partition getTransaction-0 (kafka.cluster.Partition)
[2021-04-17 04:42:26,350] INFO [Partition getTransaction-0 broker=0] Log loaded for partition getTransaction-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:28,328] INFO Creating topic getGroupDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:28,384] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:28,386] INFO [Log partition=getGroupDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:28,387] INFO Created log for partition getGroupDetails-0 in /tmp/kafka-logs/getGroupDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:28,388] INFO [Partition getGroupDetails-0 broker=0] No checkpointed highwatermark is found for partition getGroupDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:42:28,388] INFO [Partition getGroupDetails-0 broker=0] Log loaded for partition getGroupDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:30,146] INFO Creating topic getDues with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:30,231] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDues-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:30,238] INFO [Log partition=getDues-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:30,240] INFO Created log for partition getDues-0 in /tmp/kafka-logs/getDues-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:30,241] INFO [Partition getDues-0 broker=0] No checkpointed highwatermark is found for partition getDues-0 (kafka.cluster.Partition)
[2021-04-17 04:42:30,241] INFO [Partition getDues-0 broker=0] Log loaded for partition getDues-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:32,089] INFO Creating topic leaveGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:32,151] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(leaveGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:32,154] INFO [Log partition=leaveGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:32,155] INFO Created log for partition leaveGroup-0 in /tmp/kafka-logs/leaveGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:32,156] INFO [Partition leaveGroup-0 broker=0] No checkpointed highwatermark is found for partition leaveGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:42:32,156] INFO [Partition leaveGroup-0 broker=0] Log loaded for partition leaveGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:34,205] INFO Creating topic addNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:34,259] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:34,262] INFO [Log partition=addNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:34,263] INFO Created log for partition addNotes-0 in /tmp/kafka-logs/addNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:34,263] INFO [Partition addNotes-0 broker=0] No checkpointed highwatermark is found for partition addNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:42:34,263] INFO [Partition addNotes-0 broker=0] Log loaded for partition addNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:36,197] INFO Creating topic deleteNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:36,256] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(deleteNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:36,263] INFO [Log partition=deleteNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:36,266] INFO Created log for partition deleteNotes-0 in /tmp/kafka-logs/deleteNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:36,266] INFO [Partition deleteNotes-0 broker=0] No checkpointed highwatermark is found for partition deleteNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:42:36,266] INFO [Partition deleteNotes-0 broker=0] Log loaded for partition deleteNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:38,297] INFO Creating topic addExpense with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:38,371] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addExpense-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:38,377] INFO [Log partition=addExpense-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:38,379] INFO Created log for partition addExpense-0 in /tmp/kafka-logs/addExpense-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:38,380] INFO [Partition addExpense-0 broker=0] No checkpointed highwatermark is found for partition addExpense-0 (kafka.cluster.Partition)
[2021-04-17 04:42:38,380] INFO [Partition addExpense-0 broker=0] Log loaded for partition addExpense-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:42:40,396] INFO Creating topic login with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:42:40,488] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(login-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:42:40,494] INFO [Log partition=login-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:42:40,496] INFO Created log for partition login-0 in /tmp/kafka-logs/login-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:42:40,497] INFO [Partition login-0 broker=0] No checkpointed highwatermark is found for partition login-0 (kafka.cluster.Partition)
[2021-04-17 04:42:40,497] INFO [Partition login-0 broker=0] Log loaded for partition login-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:43:00,709] INFO Creating topic signUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:43:00,762] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(signUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:43:00,765] INFO [Log partition=signUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:43:00,766] INFO Created log for partition signUp-0 in /tmp/kafka-logs/signUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:43:00,766] INFO [Partition signUp-0 broker=0] No checkpointed highwatermark is found for partition signUp-0 (kafka.cluster.Partition)
[2021-04-17 04:43:00,766] INFO [Partition signUp-0 broker=0] Log loaded for partition signUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:43:42,247] INFO Creating topic response_topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:43:42,274] INFO [KafkaApi-0] Auto creation of topic response_topic with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2021-04-17 04:43:42,300] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(response_topic-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:43:42,303] INFO [Log partition=response_topic-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:43:42,304] INFO Created log for partition response_topic-0 in /tmp/kafka-logs/response_topic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:43:42,305] INFO [Partition response_topic-0 broker=0] No checkpointed highwatermark is found for partition response_topic-0 (kafka.cluster.Partition)
[2021-04-17 04:43:42,305] INFO [Partition response_topic-0 broker=0] Log loaded for partition response_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:46:34,619] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:46:34,622] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-17 04:46:34,624] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-17 04:46:34,659] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2021-04-17 04:46:34,666] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:46:34,667] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:46:34,667] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:46:34,668] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:46:34,675] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:46:34,676] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:46:34,678] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:46:34,681] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:34,699] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:34,699] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:34,700] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2021-04-17 04:46:34,700] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:34,729] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:34,729] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:34,731] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:46:34,732] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:46:34,732] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2021-04-17 04:46:34,732] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:46:34,733] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:46:34,733] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:46:34,733] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:46:34,734] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:46:34,734] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:34,807] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:34,807] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:34,808] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,007] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,007] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,009] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:46:35,011] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-17 04:46:35,011] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:46:35,012] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:46:35,012] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:46:35,013] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:46:35,016] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:46:35,017] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:46:35,017] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:46:35,018] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,215] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,215] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,215] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,222] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,222] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,222] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,422] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,422] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,423] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,429] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,429] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:46:35,463] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-17 04:46:35,464] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:46:35,465] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:46:35,465] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:46:35,465] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:46:35,467] INFO Shutting down. (kafka.log.LogManager)
[2021-04-17 04:46:35,497] INFO [ProducerStateManager partition=login-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,504] INFO [ProducerStateManager partition=getFilteredGroup-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,507] INFO [ProducerStateManager partition=response_topic-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,509] INFO [ProducerStateManager partition=getAllYouOwe-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,512] INFO [ProducerStateManager partition=getAllYouAreOwed-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,515] INFO [ProducerStateManager partition=getFriends-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,519] INFO [ProducerStateManager partition=getActiveGroups-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,522] INFO [ProducerStateManager partition=getInvites-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,524] INFO [ProducerStateManager partition=getRecentActivities-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,526] INFO [ProducerStateManager partition=getDashboardDetails-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,531] INFO [ProducerStateManager partition=getGroupsDropdown-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:46:35,628] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-17 04:46:35,643] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:46:35,643] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:46:35,643] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:46:35,645] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:46:35,764] INFO Session: 0x1002b24c9540000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:46:35,764] INFO EventThread shut down for session: 0x1002b24c9540000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:46:35,767] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:46:35,767] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:35,948] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:35,948] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:35,949] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:36,948] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:36,949] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:36,949] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:36,951] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:36,951] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:36,951] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:36,952] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:36,952] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:46:36,954] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-17 04:46:36,975] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-17 04:46:36,976] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:46:36,976] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:46:36,976] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:46:36,980] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2021-04-17 04:46:36,980] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:46:36,981] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-17 04:46:56,209] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:46:56,210] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:46:56,214] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:46:56,214] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:46:56,216] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:46:56,216] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:46:56,216] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:46:56,216] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-17 04:46:56,219] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-17 04:46:56,230] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:46:56,230] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:46:56,230] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:46:56,230] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:46:56,231] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-17 04:46:56,233] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:46:56,241] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,241] INFO Server environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:java.vendor=Ubuntu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:os.version=5.8.0-48-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,242] INFO Server environment:user.name=divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,243] INFO Server environment:user.home=/home/divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,243] INFO Server environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,243] INFO Server environment:os.memory.free=494MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,243] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,243] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,244] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,244] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,244] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:46:56,251] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-17 04:46:56,254] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:46:56,257] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:46:56,269] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-17 04:46:56,272] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:46:56,274] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:46:56,292] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-17 04:47:01,001] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-17 04:47:01,253] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-17 04:47:01,301] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:47:01,305] INFO starting (kafka.server.KafkaServer)
[2021-04-17 04:47:01,306] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-17 04:47:01,322] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:47:01,326] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,326] INFO Client environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:os.version=5.8.0-48-generic (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:user.name=divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:user.home=/home/divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,327] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,328] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,330] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@18ece7f4 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:47:01,334] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-17 04:47:01,339] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:47:01,342] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:47:01,346] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:47:01,351] INFO Socket connection established, initiating session, client: /127.0.0.1:35998, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:47:01,363] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-17 04:47:01,421] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002b29ddec0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:47:01,424] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:47:01,663] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:47:01,696] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:47:01,699] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:47:01,862] INFO Cluster ID = mZOZ3aauTA2dmgHxM7eZrQ (kafka.server.KafkaServer)
[2021-04-17 04:47:01,870] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-04-17 04:47:01,928] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:47:01,935] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:47:01,967] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:47:01,968] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:47:01,969] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:47:01,970] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:47:01,996] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2021-04-17 04:47:02,003] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2021-04-17 04:47:02,006] INFO Attempting recovery for all logs in /tmp/kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2021-04-17 04:47:02,010] INFO Loaded 0 logs in 7ms. (kafka.log.LogManager)
[2021-04-17 04:47:02,042] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-17 04:47:02,044] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-17 04:47:02,408] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:47:02,410] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:47:02,413] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:47:02,415] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-17 04:47:02,449] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:47:02,476] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:47:02,476] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:47:02,477] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:47:02,477] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:47:02,491] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:47:02,492] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:47:02,524] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-17 04:47:02,556] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1618660022542,1618660022542,1,0,0,72105052854812672,220,0,24
 (kafka.zk.KafkaZkClient)
[2021-04-17 04:47:02,557] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://divyamohan-GL552VW:9092, czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2021-04-17 04:47:02,644] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:47:02,653] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:47:02,653] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:47:02,660] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2021-04-17 04:47:02,677] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:47:02,679] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:47:02,693] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:47:02,704] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:47:02,721] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:47:02,723] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:47:02,723] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:47:02,754] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:47:02,757] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:47:02,776] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:47:02,787] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:47:02,792] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:47:02,792] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:47:02,796] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:47:02,796] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:47:02,796] INFO Kafka startTimeMs: 1618660022792 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:47:02,798] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-17 04:47:02,894] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:47:18,686] INFO Creating topic updateProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:18,820] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(updateProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:18,870] INFO [Log partition=updateProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:18,876] INFO Created log for partition updateProfile-0 in /tmp/kafka-logs/updateProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:18,877] INFO [Partition updateProfile-0 broker=0] No checkpointed highwatermark is found for partition updateProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:47:18,877] INFO [Partition updateProfile-0 broker=0] Log loaded for partition updateProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:20,895] INFO Creating topic getProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:20,949] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:20,952] INFO [Log partition=getProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:20,954] INFO Created log for partition getProfile-0 in /tmp/kafka-logs/getProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:20,954] INFO [Partition getProfile-0 broker=0] No checkpointed highwatermark is found for partition getProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:47:20,955] INFO [Partition getProfile-0 broker=0] Log loaded for partition getProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:22,639] INFO Creating topic getFriends with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:22,714] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFriends-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:22,722] INFO [Log partition=getFriends-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:22,725] INFO Created log for partition getFriends-0 in /tmp/kafka-logs/getFriends-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:22,726] INFO [Partition getFriends-0 broker=0] No checkpointed highwatermark is found for partition getFriends-0 (kafka.cluster.Partition)
[2021-04-17 04:47:22,726] INFO [Partition getFriends-0 broker=0] Log loaded for partition getFriends-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:24,478] INFO Creating topic createGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:24,546] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(createGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:24,554] INFO [Log partition=createGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:24,557] INFO Created log for partition createGroup-0 in /tmp/kafka-logs/createGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:24,558] INFO [Partition createGroup-0 broker=0] No checkpointed highwatermark is found for partition createGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:47:24,558] INFO [Partition createGroup-0 broker=0] Log loaded for partition createGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:26,406] INFO Creating topic getRecentActivities with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:26,467] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getRecentActivities-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:26,470] INFO [Log partition=getRecentActivities-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:26,472] INFO Created log for partition getRecentActivities-0 in /tmp/kafka-logs/getRecentActivities-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:26,472] INFO [Partition getRecentActivities-0 broker=0] No checkpointed highwatermark is found for partition getRecentActivities-0 (kafka.cluster.Partition)
[2021-04-17 04:47:26,473] INFO [Partition getRecentActivities-0 broker=0] Log loaded for partition getRecentActivities-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:28,212] INFO Creating topic getGroupsDropdown with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:28,312] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupsDropdown-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:28,319] INFO [Log partition=getGroupsDropdown-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:28,321] INFO Created log for partition getGroupsDropdown-0 in /tmp/kafka-logs/getGroupsDropdown-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:28,322] INFO [Partition getGroupsDropdown-0 broker=0] No checkpointed highwatermark is found for partition getGroupsDropdown-0 (kafka.cluster.Partition)
[2021-04-17 04:47:28,322] INFO [Partition getGroupsDropdown-0 broker=0] Log loaded for partition getGroupsDropdown-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:30,359] INFO Creating topic getFilteredGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:30,417] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFilteredGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:30,421] INFO [Log partition=getFilteredGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:30,422] INFO Created log for partition getFilteredGroup-0 in /tmp/kafka-logs/getFilteredGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:30,422] INFO [Partition getFilteredGroup-0 broker=0] No checkpointed highwatermark is found for partition getFilteredGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:47:30,422] INFO [Partition getFilteredGroup-0 broker=0] Log loaded for partition getFilteredGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:32,503] INFO Creating topic getDashboardDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:32,568] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDashboardDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:32,572] INFO [Log partition=getDashboardDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:32,573] INFO Created log for partition getDashboardDetails-0 in /tmp/kafka-logs/getDashboardDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:32,573] INFO [Partition getDashboardDetails-0 broker=0] No checkpointed highwatermark is found for partition getDashboardDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:47:32,574] INFO [Partition getDashboardDetails-0 broker=0] Log loaded for partition getDashboardDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:34,465] INFO Creating topic getAllYouOwe with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:34,538] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouOwe-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:34,545] INFO [Log partition=getAllYouOwe-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:34,547] INFO Created log for partition getAllYouOwe-0 in /tmp/kafka-logs/getAllYouOwe-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:34,549] INFO [Partition getAllYouOwe-0 broker=0] No checkpointed highwatermark is found for partition getAllYouOwe-0 (kafka.cluster.Partition)
[2021-04-17 04:47:34,549] INFO [Partition getAllYouOwe-0 broker=0] Log loaded for partition getAllYouOwe-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:36,358] INFO Creating topic getAllYouAreOwed with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:36,471] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouAreOwed-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:36,478] INFO [Log partition=getAllYouAreOwed-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:36,480] INFO Created log for partition getAllYouAreOwed-0 in /tmp/kafka-logs/getAllYouAreOwed-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:36,481] INFO [Partition getAllYouAreOwed-0 broker=0] No checkpointed highwatermark is found for partition getAllYouAreOwed-0 (kafka.cluster.Partition)
[2021-04-17 04:47:36,482] INFO [Partition getAllYouAreOwed-0 broker=0] Log loaded for partition getAllYouAreOwed-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:38,211] INFO Creating topic settleUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:38,289] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(settleUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:38,296] INFO [Log partition=settleUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:38,298] INFO Created log for partition settleUp-0 in /tmp/kafka-logs/settleUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:38,299] INFO [Partition settleUp-0 broker=0] No checkpointed highwatermark is found for partition settleUp-0 (kafka.cluster.Partition)
[2021-04-17 04:47:38,299] INFO [Partition settleUp-0 broker=0] Log loaded for partition settleUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:40,212] INFO Creating topic getActiveGroups with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:40,288] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getActiveGroups-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:40,295] INFO [Log partition=getActiveGroups-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:40,297] INFO Created log for partition getActiveGroups-0 in /tmp/kafka-logs/getActiveGroups-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:40,298] INFO [Partition getActiveGroups-0 broker=0] No checkpointed highwatermark is found for partition getActiveGroups-0 (kafka.cluster.Partition)
[2021-04-17 04:47:40,298] INFO [Partition getActiveGroups-0 broker=0] Log loaded for partition getActiveGroups-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:42,269] INFO Creating topic getInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:42,331] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:42,340] INFO [Log partition=getInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:42,343] INFO Created log for partition getInvites-0 in /tmp/kafka-logs/getInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:42,344] INFO [Partition getInvites-0 broker=0] No checkpointed highwatermark is found for partition getInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:47:42,345] INFO [Partition getInvites-0 broker=0] Log loaded for partition getInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:44,202] INFO Creating topic acceptInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:44,297] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(acceptInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:44,304] INFO [Log partition=acceptInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:44,306] INFO Created log for partition acceptInvites-0 in /tmp/kafka-logs/acceptInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:44,307] INFO [Partition acceptInvites-0 broker=0] No checkpointed highwatermark is found for partition acceptInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:47:44,307] INFO [Partition acceptInvites-0 broker=0] Log loaded for partition acceptInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:46,216] INFO Creating topic getAllTransactions with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:46,270] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllTransactions-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:46,272] INFO [Log partition=getAllTransactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:46,273] INFO Created log for partition getAllTransactions-0 in /tmp/kafka-logs/getAllTransactions-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:46,274] INFO [Partition getAllTransactions-0 broker=0] No checkpointed highwatermark is found for partition getAllTransactions-0 (kafka.cluster.Partition)
[2021-04-17 04:47:46,274] INFO [Partition getAllTransactions-0 broker=0] Log loaded for partition getAllTransactions-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:48,159] INFO Creating topic getTransaction with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:48,222] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getTransaction-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:48,228] INFO [Log partition=getTransaction-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:48,230] INFO Created log for partition getTransaction-0 in /tmp/kafka-logs/getTransaction-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:48,232] INFO [Partition getTransaction-0 broker=0] No checkpointed highwatermark is found for partition getTransaction-0 (kafka.cluster.Partition)
[2021-04-17 04:47:48,232] INFO [Partition getTransaction-0 broker=0] Log loaded for partition getTransaction-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:50,313] INFO Creating topic getGroupDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:50,382] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:50,388] INFO [Log partition=getGroupDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:50,391] INFO Created log for partition getGroupDetails-0 in /tmp/kafka-logs/getGroupDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:50,392] INFO [Partition getGroupDetails-0 broker=0] No checkpointed highwatermark is found for partition getGroupDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:47:50,392] INFO [Partition getGroupDetails-0 broker=0] Log loaded for partition getGroupDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:52,359] INFO Creating topic getDues with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:52,459] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDues-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:52,465] INFO [Log partition=getDues-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:52,467] INFO Created log for partition getDues-0 in /tmp/kafka-logs/getDues-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:52,468] INFO [Partition getDues-0 broker=0] No checkpointed highwatermark is found for partition getDues-0 (kafka.cluster.Partition)
[2021-04-17 04:47:52,468] INFO [Partition getDues-0 broker=0] Log loaded for partition getDues-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:54,405] INFO Creating topic leaveGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:54,481] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(leaveGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:54,486] INFO [Log partition=leaveGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:54,487] INFO Created log for partition leaveGroup-0 in /tmp/kafka-logs/leaveGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:54,487] INFO [Partition leaveGroup-0 broker=0] No checkpointed highwatermark is found for partition leaveGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:47:54,487] INFO [Partition leaveGroup-0 broker=0] Log loaded for partition leaveGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:56,181] INFO Creating topic addNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:56,274] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:56,281] INFO [Log partition=addNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:56,283] INFO Created log for partition addNotes-0 in /tmp/kafka-logs/addNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:56,284] INFO [Partition addNotes-0 broker=0] No checkpointed highwatermark is found for partition addNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:47:56,284] INFO [Partition addNotes-0 broker=0] Log loaded for partition addNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:58,025] INFO Creating topic deleteNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:58,080] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(deleteNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:58,083] INFO [Log partition=deleteNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:58,085] INFO Created log for partition deleteNotes-0 in /tmp/kafka-logs/deleteNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:58,085] INFO [Partition deleteNotes-0 broker=0] No checkpointed highwatermark is found for partition deleteNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:47:58,085] INFO [Partition deleteNotes-0 broker=0] Log loaded for partition deleteNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:47:59,789] INFO Creating topic addExpense with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:47:59,867] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addExpense-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:47:59,874] INFO [Log partition=addExpense-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:47:59,876] INFO Created log for partition addExpense-0 in /tmp/kafka-logs/addExpense-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:47:59,878] INFO [Partition addExpense-0 broker=0] No checkpointed highwatermark is found for partition addExpense-0 (kafka.cluster.Partition)
[2021-04-17 04:47:59,878] INFO [Partition addExpense-0 broker=0] Log loaded for partition addExpense-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:48:01,759] INFO Creating topic login with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:48:01,884] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(login-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:48:01,890] INFO [Log partition=login-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:48:01,892] INFO Created log for partition login-0 in /tmp/kafka-logs/login-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:48:01,893] INFO [Partition login-0 broker=0] No checkpointed highwatermark is found for partition login-0 (kafka.cluster.Partition)
[2021-04-17 04:48:01,893] INFO [Partition login-0 broker=0] Log loaded for partition login-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:48:03,834] INFO Creating topic signUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:48:03,906] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(signUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:48:03,910] INFO [Log partition=signUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:48:03,911] INFO Created log for partition signUp-0 in /tmp/kafka-logs/signUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:48:03,911] INFO [Partition signUp-0 broker=0] No checkpointed highwatermark is found for partition signUp-0 (kafka.cluster.Partition)
[2021-04-17 04:48:03,911] INFO [Partition signUp-0 broker=0] Log loaded for partition signUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:49:33,263] INFO Creating topic response_topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:49:33,312] INFO [KafkaApi-0] Auto creation of topic response_topic with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2021-04-17 04:49:33,338] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(response_topic-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:49:33,341] INFO [Log partition=response_topic-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:49:33,342] INFO Created log for partition response_topic-0 in /tmp/kafka-logs/response_topic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:49:33,342] INFO [Partition response_topic-0 broker=0] No checkpointed highwatermark is found for partition response_topic-0 (kafka.cluster.Partition)
[2021-04-17 04:49:33,342] INFO [Partition response_topic-0 broker=0] Log loaded for partition response_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:58:31,413] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:58:31,417] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-17 04:58:31,419] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-17 04:58:31,464] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2021-04-17 04:58:31,469] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:58:31,469] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:58:31,469] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:58:31,470] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:58:31,476] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-17 04:58:31,477] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:58:31,480] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2021-04-17 04:58:31,482] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:31,647] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:31,647] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:31,649] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2021-04-17 04:58:31,651] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:31,819] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:31,819] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:31,822] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:58:31,824] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:58:31,825] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2021-04-17 04:58:31,825] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:58:31,825] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:58:31,826] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:58:31,827] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:58:31,828] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:58:31,829] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:31,938] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:31,938] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:31,939] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,136] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,136] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,137] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:58:32,139] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-17 04:58:32,140] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:58:32,140] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:58:32,140] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:58:32,141] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:58:32,144] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:58:32,145] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:58:32,146] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-17 04:58:32,146] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,180] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,180] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,181] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,338] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,338] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,339] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,536] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,536] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,537] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,736] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,736] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:32,777] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-17 04:58:32,777] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:58:32,778] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:58:32,778] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:58:32,778] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:58:32,780] INFO Shutting down. (kafka.log.LogManager)
[2021-04-17 04:58:32,808] INFO [ProducerStateManager partition=login-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,816] INFO [ProducerStateManager partition=getFilteredGroup-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,821] INFO [ProducerStateManager partition=response_topic-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,824] INFO [ProducerStateManager partition=getAllYouOwe-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,827] INFO [ProducerStateManager partition=getAllYouAreOwed-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,831] INFO [ProducerStateManager partition=getFriends-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,835] INFO [ProducerStateManager partition=getActiveGroups-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,839] INFO [ProducerStateManager partition=getInvites-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,842] INFO [ProducerStateManager partition=getRecentActivities-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,844] INFO [ProducerStateManager partition=getDashboardDetails-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,849] INFO [ProducerStateManager partition=getGroupsDropdown-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2021-04-17 04:58:32,950] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-17 04:58:32,963] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:58:32,964] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:58:32,964] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:58:32,966] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:58:33,082] INFO Session: 0x1002b29ddec0000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:33,082] INFO EventThread shut down for session: 0x1002b29ddec0000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:58:33,085] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:58:33,086] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:34,057] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:34,057] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:34,057] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:35,057] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:35,057] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:35,058] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:36,058] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:36,058] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:36,058] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:37,058] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:37,058] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:37,060] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-17 04:58:37,104] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-17 04:58:37,104] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:58:37,104] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:58:37,104] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2021-04-17 04:58:37,109] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2021-04-17 04:58:37,110] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:58:37,110] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-17 04:58:42,951] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:58:42,952] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:58:42,959] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:58:42,959] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:58:42,961] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:58:42,962] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:58:42,962] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-17 04:58:42,962] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-17 04:58:42,967] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-17 04:58:42,983] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:58:42,983] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:58:42,983] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:58:42,983] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-17 04:58:42,983] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-17 04:58:42,987] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:58:42,995] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,995] INFO Server environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:java.vendor=Ubuntu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:os.version=5.8.0-48-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:user.name=divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:user.home=/home/divyamohan (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,996] INFO Server environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,997] INFO Server environment:os.memory.free=494MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,997] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,997] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,998] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,998] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:42,998] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-17 04:58:43,005] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-17 04:58:43,008] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:58:43,012] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-17 04:58:43,028] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-17 04:58:43,031] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:58:43,034] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-17 04:58:43,051] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-17 04:58:49,726] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-17 04:58:49,975] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-17 04:58:50,024] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-04-17 04:58:50,028] INFO starting (kafka.server.KafkaServer)
[2021-04-17 04:58:50,029] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-17 04:58:50,046] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:58:50,051] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,051] INFO Client environment:host.name=divyamohan-GL552VW (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,051] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,051] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,051] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,051] INFO Client environment:java.class.path=/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/divyamohan/Downloads/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,051] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,051] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:os.version=5.8.0-48-generic (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:user.name=divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:user.home=/home/divyamohan (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:user.dir=/home/divyamohan/Downloads/kafka_2.13-2.7.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,052] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,054] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@18ece7f4 (org.apache.zookeeper.ZooKeeper)
[2021-04-17 04:58:50,058] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-17 04:58:50,062] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:58:50,065] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:58:50,069] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:58:50,074] INFO Socket connection established, initiating session, client: /127.0.0.1:42938, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:58:50,086] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-17 04:58:50,160] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002b34a6b40000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-17 04:58:50,167] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-17 04:58:50,417] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-04-17 04:58:50,450] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:58:50,453] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:58:50,632] INFO Cluster ID = Tk_udGPATTiMo4I-bb2CoQ (kafka.server.KafkaServer)
[2021-04-17 04:58:50,637] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-04-17 04:58:50,696] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:58:50,704] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-17 04:58:50,743] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:50,743] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:50,744] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:50,746] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-17 04:58:50,766] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2021-04-17 04:58:50,772] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2021-04-17 04:58:50,783] INFO Attempting recovery for all logs in /tmp/kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2021-04-17 04:58:50,787] INFO Loaded 0 logs in 15ms. (kafka.log.LogManager)
[2021-04-17 04:58:50,806] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-17 04:58:50,809] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-17 04:58:51,162] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:58:51,165] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:58:51,168] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-04-17 04:58:51,171] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-17 04:58:51,207] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:58:51,235] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:51,236] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:51,237] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:51,237] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:51,251] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-17 04:58:51,251] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:58:51,291] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-17 04:58:51,336] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1618660731310,1618660731310,1,0,0,72105099173036032,220,0,24
 (kafka.zk.KafkaZkClient)
[2021-04-17 04:58:51,338] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://divyamohan-GL552VW:9092, czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2021-04-17 04:58:51,436] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:51,443] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:51,444] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:51,457] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2021-04-17 04:58:51,470] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:58:51,471] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-17 04:58:51,482] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2021-04-17 04:58:51,492] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-17 04:58:51,512] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:58:51,514] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-17 04:58:51,514] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-17 04:58:51,545] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-17 04:58:51,548] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-04-17 04:58:51,562] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-17 04:58:51,574] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:58:51,579] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-04-17 04:58:51,579] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-04-17 04:58:51,583] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:58:51,583] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:58:51,584] INFO Kafka startTimeMs: 1618660731580 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-17 04:58:51,585] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-17 04:58:51,754] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-04-17 04:59:08,225] INFO Creating topic updateProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:08,344] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(updateProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:08,389] INFO [Log partition=updateProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:08,395] INFO Created log for partition updateProfile-0 in /tmp/kafka-logs/updateProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:08,395] INFO [Partition updateProfile-0 broker=0] No checkpointed highwatermark is found for partition updateProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:59:08,396] INFO [Partition updateProfile-0 broker=0] Log loaded for partition updateProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:10,135] INFO Creating topic getProfile with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:10,207] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getProfile-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:10,213] INFO [Log partition=getProfile-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:10,216] INFO Created log for partition getProfile-0 in /tmp/kafka-logs/getProfile-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:10,216] INFO [Partition getProfile-0 broker=0] No checkpointed highwatermark is found for partition getProfile-0 (kafka.cluster.Partition)
[2021-04-17 04:59:10,217] INFO [Partition getProfile-0 broker=0] Log loaded for partition getProfile-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:12,095] INFO Creating topic getFriends with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:12,154] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFriends-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:12,159] INFO [Log partition=getFriends-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:12,161] INFO Created log for partition getFriends-0 in /tmp/kafka-logs/getFriends-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:12,161] INFO [Partition getFriends-0 broker=0] No checkpointed highwatermark is found for partition getFriends-0 (kafka.cluster.Partition)
[2021-04-17 04:59:12,161] INFO [Partition getFriends-0 broker=0] Log loaded for partition getFriends-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:13,890] INFO Creating topic createGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:13,950] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(createGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:13,958] INFO [Log partition=createGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:13,960] INFO Created log for partition createGroup-0 in /tmp/kafka-logs/createGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:13,962] INFO [Partition createGroup-0 broker=0] No checkpointed highwatermark is found for partition createGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:59:13,962] INFO [Partition createGroup-0 broker=0] Log loaded for partition createGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:15,990] INFO Creating topic getRecentActivities with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:16,058] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getRecentActivities-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:16,065] INFO [Log partition=getRecentActivities-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:16,068] INFO Created log for partition getRecentActivities-0 in /tmp/kafka-logs/getRecentActivities-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:16,069] INFO [Partition getRecentActivities-0 broker=0] No checkpointed highwatermark is found for partition getRecentActivities-0 (kafka.cluster.Partition)
[2021-04-17 04:59:16,069] INFO [Partition getRecentActivities-0 broker=0] Log loaded for partition getRecentActivities-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:18,150] INFO Creating topic getGroupsDropdown with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:18,254] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupsDropdown-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:18,265] INFO [Log partition=getGroupsDropdown-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:18,268] INFO Created log for partition getGroupsDropdown-0 in /tmp/kafka-logs/getGroupsDropdown-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:18,269] INFO [Partition getGroupsDropdown-0 broker=0] No checkpointed highwatermark is found for partition getGroupsDropdown-0 (kafka.cluster.Partition)
[2021-04-17 04:59:18,269] INFO [Partition getGroupsDropdown-0 broker=0] Log loaded for partition getGroupsDropdown-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:20,168] INFO Creating topic getFilteredGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:20,231] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getFilteredGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:20,236] INFO [Log partition=getFilteredGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:20,237] INFO Created log for partition getFilteredGroup-0 in /tmp/kafka-logs/getFilteredGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:20,238] INFO [Partition getFilteredGroup-0 broker=0] No checkpointed highwatermark is found for partition getFilteredGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:59:20,238] INFO [Partition getFilteredGroup-0 broker=0] Log loaded for partition getFilteredGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:22,122] INFO Creating topic getDashboardDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:22,190] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDashboardDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:22,196] INFO [Log partition=getDashboardDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:22,197] INFO Created log for partition getDashboardDetails-0 in /tmp/kafka-logs/getDashboardDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:22,198] INFO [Partition getDashboardDetails-0 broker=0] No checkpointed highwatermark is found for partition getDashboardDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:59:22,198] INFO [Partition getDashboardDetails-0 broker=0] Log loaded for partition getDashboardDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:24,250] INFO Creating topic getAllYouOwe with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:24,317] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouOwe-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:24,323] INFO [Log partition=getAllYouOwe-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:24,326] INFO Created log for partition getAllYouOwe-0 in /tmp/kafka-logs/getAllYouOwe-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:24,326] INFO [Partition getAllYouOwe-0 broker=0] No checkpointed highwatermark is found for partition getAllYouOwe-0 (kafka.cluster.Partition)
[2021-04-17 04:59:24,327] INFO [Partition getAllYouOwe-0 broker=0] Log loaded for partition getAllYouOwe-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:26,199] INFO Creating topic getAllYouAreOwed with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:26,292] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllYouAreOwed-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:26,299] INFO [Log partition=getAllYouAreOwed-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:26,302] INFO Created log for partition getAllYouAreOwed-0 in /tmp/kafka-logs/getAllYouAreOwed-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:26,303] INFO [Partition getAllYouAreOwed-0 broker=0] No checkpointed highwatermark is found for partition getAllYouAreOwed-0 (kafka.cluster.Partition)
[2021-04-17 04:59:26,303] INFO [Partition getAllYouAreOwed-0 broker=0] Log loaded for partition getAllYouAreOwed-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:28,243] INFO Creating topic settleUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:28,297] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(settleUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:28,300] INFO [Log partition=settleUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:28,301] INFO Created log for partition settleUp-0 in /tmp/kafka-logs/settleUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:28,301] INFO [Partition settleUp-0 broker=0] No checkpointed highwatermark is found for partition settleUp-0 (kafka.cluster.Partition)
[2021-04-17 04:59:28,302] INFO [Partition settleUp-0 broker=0] Log loaded for partition settleUp-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:30,131] INFO Creating topic getActiveGroups with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:30,189] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getActiveGroups-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:30,193] INFO [Log partition=getActiveGroups-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:30,194] INFO Created log for partition getActiveGroups-0 in /tmp/kafka-logs/getActiveGroups-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:30,195] INFO [Partition getActiveGroups-0 broker=0] No checkpointed highwatermark is found for partition getActiveGroups-0 (kafka.cluster.Partition)
[2021-04-17 04:59:30,195] INFO [Partition getActiveGroups-0 broker=0] Log loaded for partition getActiveGroups-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:31,967] INFO Creating topic getInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:32,028] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:32,036] INFO [Log partition=getInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:32,039] INFO Created log for partition getInvites-0 in /tmp/kafka-logs/getInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:32,041] INFO [Partition getInvites-0 broker=0] No checkpointed highwatermark is found for partition getInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:59:32,041] INFO [Partition getInvites-0 broker=0] Log loaded for partition getInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:33,878] INFO Creating topic acceptInvites with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:33,960] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(acceptInvites-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:33,968] INFO [Log partition=acceptInvites-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:33,971] INFO Created log for partition acceptInvites-0 in /tmp/kafka-logs/acceptInvites-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:33,973] INFO [Partition acceptInvites-0 broker=0] No checkpointed highwatermark is found for partition acceptInvites-0 (kafka.cluster.Partition)
[2021-04-17 04:59:33,973] INFO [Partition acceptInvites-0 broker=0] Log loaded for partition acceptInvites-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:35,866] INFO Creating topic getAllTransactions with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:35,923] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getAllTransactions-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:35,926] INFO [Log partition=getAllTransactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:35,928] INFO Created log for partition getAllTransactions-0 in /tmp/kafka-logs/getAllTransactions-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:35,928] INFO [Partition getAllTransactions-0 broker=0] No checkpointed highwatermark is found for partition getAllTransactions-0 (kafka.cluster.Partition)
[2021-04-17 04:59:35,928] INFO [Partition getAllTransactions-0 broker=0] Log loaded for partition getAllTransactions-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:37,623] INFO Creating topic getTransaction with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:37,693] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getTransaction-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:37,700] INFO [Log partition=getTransaction-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:37,702] INFO Created log for partition getTransaction-0 in /tmp/kafka-logs/getTransaction-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:37,703] INFO [Partition getTransaction-0 broker=0] No checkpointed highwatermark is found for partition getTransaction-0 (kafka.cluster.Partition)
[2021-04-17 04:59:37,703] INFO [Partition getTransaction-0 broker=0] Log loaded for partition getTransaction-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:39,725] INFO Creating topic getGroupDetails with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:39,790] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getGroupDetails-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:39,793] INFO [Log partition=getGroupDetails-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:39,794] INFO Created log for partition getGroupDetails-0 in /tmp/kafka-logs/getGroupDetails-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:39,794] INFO [Partition getGroupDetails-0 broker=0] No checkpointed highwatermark is found for partition getGroupDetails-0 (kafka.cluster.Partition)
[2021-04-17 04:59:39,794] INFO [Partition getGroupDetails-0 broker=0] Log loaded for partition getGroupDetails-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:41,413] INFO Creating topic getDues with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:41,503] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getDues-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:41,509] INFO [Log partition=getDues-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:41,511] INFO Created log for partition getDues-0 in /tmp/kafka-logs/getDues-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:41,512] INFO [Partition getDues-0 broker=0] No checkpointed highwatermark is found for partition getDues-0 (kafka.cluster.Partition)
[2021-04-17 04:59:41,513] INFO [Partition getDues-0 broker=0] Log loaded for partition getDues-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:43,234] INFO Creating topic leaveGroup with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:43,300] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(leaveGroup-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:43,304] INFO [Log partition=leaveGroup-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:43,305] INFO Created log for partition leaveGroup-0 in /tmp/kafka-logs/leaveGroup-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:43,306] INFO [Partition leaveGroup-0 broker=0] No checkpointed highwatermark is found for partition leaveGroup-0 (kafka.cluster.Partition)
[2021-04-17 04:59:43,306] INFO [Partition leaveGroup-0 broker=0] Log loaded for partition leaveGroup-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:45,188] INFO Creating topic addNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:45,241] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:45,243] INFO [Log partition=addNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:45,244] INFO Created log for partition addNotes-0 in /tmp/kafka-logs/addNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:45,244] INFO [Partition addNotes-0 broker=0] No checkpointed highwatermark is found for partition addNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:59:45,244] INFO [Partition addNotes-0 broker=0] Log loaded for partition addNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:47,011] INFO Creating topic deleteNotes with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:47,066] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(deleteNotes-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:47,069] INFO [Log partition=deleteNotes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:47,069] INFO Created log for partition deleteNotes-0 in /tmp/kafka-logs/deleteNotes-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:47,070] INFO [Partition deleteNotes-0 broker=0] No checkpointed highwatermark is found for partition deleteNotes-0 (kafka.cluster.Partition)
[2021-04-17 04:59:47,070] INFO [Partition deleteNotes-0 broker=0] Log loaded for partition deleteNotes-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:49,020] INFO Creating topic addExpense with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:49,078] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(addExpense-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:49,084] INFO [Log partition=addExpense-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:49,086] INFO Created log for partition addExpense-0 in /tmp/kafka-logs/addExpense-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:49,087] INFO [Partition addExpense-0 broker=0] No checkpointed highwatermark is found for partition addExpense-0 (kafka.cluster.Partition)
[2021-04-17 04:59:49,087] INFO [Partition addExpense-0 broker=0] Log loaded for partition addExpense-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:50,950] INFO Creating topic login with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:51,045] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(login-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:51,052] INFO [Log partition=login-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:51,054] INFO Created log for partition login-0 in /tmp/kafka-logs/login-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:51,055] INFO [Partition login-0 broker=0] No checkpointed highwatermark is found for partition login-0 (kafka.cluster.Partition)
[2021-04-17 04:59:51,055] INFO [Partition login-0 broker=0] Log loaded for partition login-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-17 04:59:53,142] INFO Creating topic signUp with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-17 04:59:53,200] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(signUp-0) (kafka.server.ReplicaFetcherManager)
[2021-04-17 04:59:53,203] INFO [Log partition=signUp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-17 04:59:53,204] INFO Created log for partition signUp-0 in /tmp/kafka-logs/signUp-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-17 04:59:53,204] INFO [Partition signUp-0 broker=0] No checkpointed highwatermark is found for partition signUp-0 (kafka.cluster.Partition)
[2021-04-17 04:59:53,204] INFO [Partition signUp-0 broker=0] Log loaded for partition signUp-0 with initial high watermark 0 (kafka.cluster.Partition)
